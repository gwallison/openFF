{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9c7fc4-03cf-493c-839f-2406769e7b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'c:/MyDocs/integrated/') # adjust to your setup\n",
    "\n",
    "%run \"catalog_support.py\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68199e2-8615-4b62-ae24-56d2bf5602a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alldf = pd.read_parquet(os.path.join(hndl.sandbox_dir,'state.parquet'))\n",
    "alldf.date = pd.to_datetime(alldf.date)\n",
    "statename = alldf.bgStateName.iloc[0]\n",
    "state_file_handle = statename.replace(' ','_')\n",
    "\n",
    "hide_blog_links = ['idaho','indiana','illinois','nevada', 'nebraska','michigan',\n",
    "                   'kentucky','mississippi','alabama']\n",
    "# print(alldf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f56f1bc-d03d-42b0-864e-00d2080876f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print( th.getMoleculeImg(cas,size=300))\n",
    "showHeader(statename.title(), link_up_level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5dc391-f59e-4ca2-bc7b-369bc93e4e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f943be2b-47b3-4235-8c97-de2cbad26468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state abbreviations\n",
    "s = \"\"\"\n",
    "ALABAMA\tAL\n",
    "ALASKA\tAK\n",
    "ARIZONA\tAZ\n",
    "ARKANSAS\tAR\n",
    "CALIFORNIA\tCA\n",
    "COLORADO\tCO\n",
    "CONNECTICUT\tCT\n",
    "DELAWARE\tDE\n",
    "FLORIDA\tFL\n",
    "GEORGIA\tGA\n",
    "HAWAII\tHI\n",
    "IDAHO\tID\n",
    "ILLINOIS\tIL\n",
    "INDIANA\tIN\n",
    "IOWA\tIA\n",
    "KANSAS\tKS\n",
    "KENTUCKY\tKY\n",
    "LOUISIANA\tLA\n",
    "MAINE\tME\n",
    "MARYLAND\tMD\n",
    "MASSACHUSETTS\tMA\n",
    "MICHIGAN\tMI\n",
    "MINNESOTA\tMN\n",
    "MISSISSIPPI\tMS\n",
    "MISSOURI\tMO\n",
    "MONTANA\tMT\n",
    "NEBRASKA\tNE\n",
    "NEVADA\tNV\n",
    "NEW HAMPSHIRE\tNH\n",
    "NEW JERSEY\tNJ\n",
    "NEW MEXICO\tNM\n",
    "NEW YORK\tNY\n",
    "NORTH CAROLINA\tNC\n",
    "NORTH DAKOTA\tND\n",
    "OHIO\tOH\n",
    "OKLAHOMA\tOK\n",
    "OREGON\tOR\n",
    "PENNSYLVANIA\tPA\n",
    "RHODE ISLAND\tRI\n",
    "SOUTH CAROLINA\tSC\n",
    "SOUTH DAKOTA\tSD\n",
    "TENNESSEE\tTN\n",
    "TEXAS\tTX\n",
    "UTAH\tUT\n",
    "VERMONT\tVT\n",
    "VIRGINIA\tVA\n",
    "WASHINGTON\tWA\n",
    "WEST VIRGINIA\tWV\n",
    "WISCONSIN\tWI\n",
    "WYOMING\tWY\n",
    "MEXICO_MX\n",
    "CANADA_CN\n",
    "\n",
    "\"\"\"\n",
    "s = s.replace('\\t','_')\n",
    "state_abbv_dic = {}\n",
    "for line in s.split('\\n'):\n",
    "    tup = tuple(line.split('_'))\n",
    "    try:\n",
    "        state_abbv_dic[tup[0].lower()] = tup[1]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "my_state_abbv = state_abbv_dic[statename]\n",
    "# print(my_state_abbv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c11d121-ab1a-41d5-b5ba-8d45147ffac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get watershed df for determining which sheds to plot\n",
    "#!!!! Need to move this to the caller! don't run with every watershed!\n",
    "import geopandas as gpd\n",
    "# gdb_path =  r\"C:\\MyDocs\\integrated\\ext_data\\WBD_National_GDB.zip\"\n",
    "# huc8_layer_name = 'WBDHU8'  # Example layer name, use the one you found\n",
    "#!!!!!\n",
    "\n",
    "# Read the specific layer into a GeoDataFrame\n",
    "# huc8_gdf = gpd.read_file(gdb_path, layer=huc8_layer_name)\n",
    "# huc8_gdf = huc8_gdf.drop('loaddate',axis=1)\n",
    "# huc8_gdf.to_parquet(os.path.join(hndl.sandbox_dir,'huc8_gdf.parquet'))\n",
    "\n",
    "huc8_gdf = gpd.read_parquet(os.path.join(hndl.sandbox_dir,'huc8_gdf.parquet'))\n",
    "huc8_gdf['huc8_name'] = huc8_gdf['name']\n",
    "# print(huc8_gdf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a5cf5c-9ee6-4cee-bbec-830a875e1307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xlate_val(n):\n",
    "    if n==0:\n",
    "        return ''\n",
    "    if n<1000:\n",
    "        return round_sig(n,1)\n",
    "    x = round_sig(n,1)\n",
    "    return x[0]+ 'k'\n",
    "\n",
    "def make_annot(gb):\n",
    "    annot = gb.copy()\n",
    "    annot.DisclosureId = annot.DisclosureId.map(lambda x: xlate_val(x))\n",
    "    #print(annot)\n",
    "    piv = annot.pivot(index='County',columns='year',values='DisclosureId')\n",
    "    piv.fillna('',inplace=True)\n",
    "    #print(piv)\n",
    "    return piv\n",
    "\n",
    "def get_state_center(state):\n",
    "    t = pd.read_csv(r\"C:\\MyDocs\\OpenFF\\src\\openFF-catalog\\work\\state_coords.csv\",\n",
    "                   dtype={'Latitude':'float', 'Longitude':'float'})\n",
    "    t = t[t.state==state]\n",
    "    #print(t)\n",
    "    return [t.Latitude.mean(),t.Longitude.mean()*-1]\n",
    "\n",
    "# mapping code - much lifted from core.mapping\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import openFF.common.text_handlers as th\n",
    "\n",
    "final_crs = 4326 # WGS84\n",
    "proj_crs = 3857 # convert to this when calculating distances\n",
    "def_buffer = 1609.34 # one mile\n",
    "\n",
    "def prep_shape(statename='ohio'):\n",
    "    fn = r\"C:\\MyDocs\\integrated\\ext_data\\georef-united-states-of-america-state.geojson\"\n",
    "    geojson = gpd.read_file(fn)\n",
    "    geojson['StateName'] = geojson.ste_name.str.lower()\n",
    "    # print(geojson.StateName)\n",
    "    # geojson['CountyName'] = geojson.coty_name.str.lower()\n",
    "    # geojson = mapping.fix_county_names(geojson)\n",
    "    geojson = geojson[(geojson.StateName==statename)]\n",
    "    return geojson\n",
    "    \n",
    "def CountyMap(df):\n",
    "    start_loc = get_state_center(statename)\n",
    "    #print(statename,start_loc)\n",
    "    cond = ~df.location_error\n",
    "    if cond.sum()==0:  # no valid fracks for this state\n",
    "        display(md(f'### No mappable fracks for {statename}!'))\n",
    "        display(md(f'This is usually caused when \"CountyName\" in FracFocus dont match standard names'))\n",
    "        return\n",
    "    gb = df[cond].groupby(['bgStateName','bgCountyName',\n",
    "                                                   'DisclosureId'],as_index=False).size()\n",
    "    gb = gb.groupby(['bgStateName','bgCountyName'],as_index=False)['DisclosureId'].count().rename({'bgStateName':'StateName',\n",
    "                                                                                                'bgCountyName':'CountyName',\n",
    "                                                                                                'DisclosureId':'value'},\n",
    "                                                                                                axis=1)\n",
    "    zoom = 6\n",
    "    if statename in ['texas','california']:\n",
    "        zoom = 5\n",
    "    if statename in ['alaska']:\n",
    "        zoom = 4\n",
    "\n",
    "    geojson = prep_shape(statename)\n",
    "\n",
    "    fig = mapping.create_county_choropleth(gb,include_shape=True,area_df=geojson,\n",
    "                             plotlog=True,custom_scale= [0,1,2,3,4,5],\n",
    "                             start_loc=start_loc, # center of state's data\n",
    "                             legend_name='Number of FracFocus disclosures',\n",
    "                             start_zoom=zoom,fields=['StateName','CountyName','orig_value','county_link'],\n",
    "                             aliases=['State: ','County: ','Number Fracking disclosures: ','Link to county page: '])\n",
    "    \n",
    "    fn = os.path.join(hndl.browser_states_dir,state_file_handle,'county_choropleth.html')\n",
    "    fig.save(fn)\n",
    "\n",
    "def CountyCntTable(df):\n",
    "    # first, make the general searchable table\n",
    "    gb = df.groupby(['bgCountyName','DisclosureId'],as_index=False)['date'].first()\n",
    "    gb['year'] = gb.date.dt.year.astype('str')\n",
    "    gb1 = gb.groupby(['bgCountyName'],as_index=False)['DisclosureId'].count().rename({'DisclosureId':'disclosure_count'},\n",
    "                                                                                  axis=1)\n",
    "    gb2 = gb1.copy()\n",
    "    gbop = df.groupby('bgCountyName')['OperatorName'].agg(lambda x:x.value_counts().index[0:4]).reset_index()\n",
    "    gbop.OperatorName = gbop.OperatorName.map(lambda x: th.xlate_to_str(x,'; ',sort=False))\n",
    "    gbop = gbop.rename({'OperatorName':'Top Operators'},axis=1)\n",
    "    gb2 = pd.merge(gb2,gbop,on='bgCountyName',how='left')\n",
    "\n",
    "#     gbprop = df[df.bgCAS=='proprietary'].groupby('bgCountyName',as_index=False).size()\n",
    "# #     gbprop.bgCAS.fillna(0,inplace=True)\n",
    "#     gbprop = gbprop.rename({'size':'Trade Secret records'},axis=1)\n",
    "#     gb2 = pd.merge(gb2,gbprop,on='bgCountyName',how='left')\n",
    "#     gb2['Trade Secret records'].fillna(0,inplace=True)\n",
    "    \n",
    "    gbtbwv = df.groupby(['bgCountyName','DisclosureId'],as_index=False)['TotalBaseWaterVolume'].first()\n",
    "    gbtbwv = gbtbwv.groupby('bgCountyName',as_index=False)['TotalBaseWaterVolume'].sum().rename({'TotalBaseWaterVolume':'tot_gallons_water'},\n",
    "                                                                                                axis=1)\n",
    "    gbtbwv.tot_gallons_water = gbtbwv.tot_gallons_water.map(lambda x: th.round_sig(x,3))\n",
    "    gb2 = pd.merge(gb2,gbtbwv,on='bgCountyName',how='left')\n",
    "\n",
    "    #print(gb2.head())\n",
    "    gb2['County'] = '<center><h4>'+gb2.bgCountyName.str.title().map(lambda x: th.getCountyLink(x,statename,x))+'</h4></center>'\n",
    "    gb2 = gb2.drop('bgCountyName',axis=1)\n",
    "    iShow(gb2.sort_values('disclosure_count',ascending=False)[['County','disclosure_count',\n",
    "                                                               #'Trade Secret records'\n",
    "                                                               'tot_gallons_water',\n",
    "                                                               'Top Operators']].reset_index(drop=True),\n",
    "         classes=\"display compact cell-border\")\n",
    "\n",
    "def fetch_watersheds_for_state(state_abbv=my_state_abbv):\n",
    "    c1 = huc8_gdf.states.str.contains(state_abbv)\n",
    "    out = huc8_gdf[c1]\n",
    "    # print(f'Of {len(huc8_gdf)} watersheds, returning {len(huc8_gdf[c1])}')\n",
    "    return out\n",
    "\n",
    "def WatershedMap(df):\n",
    "    start_loc = get_state_center(statename)\n",
    "\n",
    "    fn = r\"C:\\MyDocs\\OpenFF\\data\\non-FF\\georef-united-states-of-america-state.geojson\"\n",
    "    statejson = gpd.read_file(fn)\n",
    "    statejson['StateName'] = statejson.ste_name.str.lower()\n",
    "    # geojson['CountyName'] = geojson.coty_name.str.lower()\n",
    "    # geojson = mapping.fix_county_names(geojson)\n",
    "    # geojson = geojson[(geojson.StateName==statename)&(geojson.CountyName==countyname)]\n",
    "    statejson = statejson[statejson.StateName==statename]\n",
    "    \n",
    "    #print(statename,start_loc)\n",
    "    # cond = ~df.location_error\n",
    "    # if cond.sum()==0:  # no valid fracks for this state\n",
    "    #     display(md(f'### No mappable fracks for {statename}!'))\n",
    "    #     display(md(f'This is usually caused when \"CountyName\" in FracFocus dont match standard names'))\n",
    "    #     return\n",
    "    gb = df.groupby(['huc8','DisclosureId'],as_index=False).size()\n",
    "    gb = gb.groupby(['huc8'],as_index=False).size().rename({'size':'value'},axis=1)\n",
    "    gb['statename'] = statename\n",
    "    zoom = 6\n",
    "    if statename in ['texas','california']:\n",
    "        zoom = 5\n",
    "    if statename in ['alaska']:\n",
    "        zoom = 4\n",
    "\n",
    "    geojson = fetch_watersheds_for_state()\n",
    "    # print(geojson.columns)\n",
    "    fig = mapping.create_watershed_choropleth(gb,include_shape=True,area_df=geojson,\n",
    "                                              include_state=True,state_df=statejson,\n",
    "                             plotlog=True,custom_scale= [0,1,2,3,4,5],\n",
    "                             start_loc=start_loc, # center of state's data\n",
    "                             legend_name='Number of FracFocus disclosures',\n",
    "                             start_zoom=zoom,fields=['huc8_name','huc8','orig_value','watershed_link'],\n",
    "                             aliases=['Watershed name: ','Watershed code: ','Number Fracking disclosures: ','Link to watershed page: ']\n",
    "                                          )\n",
    "    \n",
    "    # fn = os.path.join(hndl.browser_states_dir,state_file_handle,'county_choropleth.html')\n",
    "    # fig.save(fn)\n",
    "\n",
    "# states_sheds = fetch_watersheds_for_state()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cfcc01-ea07-409f-bf2b-25eda753259f",
   "metadata": {},
   "source": [
    "---\n",
    "# Links and Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21666c8f-9b8c-407b-81b7-08411190d071",
   "metadata": {},
   "outputs": [],
   "source": [
    "sn = statename.replace(' ','-')\n",
    "s = ''\n",
    "if not statename in hide_blog_links:\n",
    "    s+= f\"> **[Open-FF summary stats and posts about {statename.title()}](https://open-ff.org/{sn}-fracfocus/)**<br>\"\n",
    "s+= f\"**[FracTracker Alliance maps of {statename.title()}](https://www.fractracker.org/map/us/{sn}/)**\"\n",
    "display(md(s))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f59e4fa8-3718-404c-ba94-b6df3140f477",
   "metadata": {},
   "source": [
    "# Where are the fracking locations in this state?\n",
    "This is not an exhaustive set of wells in these counties; it is only those wells for which the operating company submits a chemical disclosure to FracFocus.  In addition, this map omits disclosures for which location information is conflicting, such as the Latitude/Longitude values are outside of the reported county.\n",
    "\n",
    "### by county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3860db3-6c4d-4dea-9e64-38efc5776d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "CountyMap(alldf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33655539-c48f-4034-b458-b7dac50cfd7c",
   "metadata": {},
   "source": [
    "### by watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a28680-8a9e-4053-9d77-68f26c2438fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "WatershedMap(alldf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a6c5eb-d079-425c-9b4f-715723e98bb3",
   "metadata": {},
   "source": [
    "---\n",
    "## Number of disclosures per month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b91771b-d18f-4bdf-be15-6b77e7a384e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = alldf.groupby('DisclosureId',as_index=False)[['date','no_chem_recs']].first()\n",
    "gb = gb[gb.date.dt.year>2010]\n",
    "# gb1 = alldf.groupby('DisclosureId',as_index=False)['ingKeyPresent'].sum()\n",
    "# mg = pd.merge(gb,gb1,on='DisclosureId',how='left')\n",
    "gb2 = gb[~gb.no_chem_recs].groupby('date').size()\n",
    "allwk_sum = gb2.resample(\"M\").sum()\n",
    "ax = allwk_sum.plot(figsize=(7,5), ylabel='Number of disclosures',label='with chemical records');\n",
    "ax.set_title(f'Monthly Number of {statename.title()} Disclosures',fontsize=15);\n",
    "\n",
    "\n",
    "gb3 = gb[gb.no_chem_recs].groupby('date').size()\n",
    "# alldfv1 = master_df[~master_df.ingKeyPresent].groupby('DisclosureId',as_index=False)[['date','TotalBaseWaterVolume']].first()\n",
    "# gbv1 = gb3.groupby('date').size()\n",
    "allwk_sumv1 = gb3.resample(\"m\").sum()\n",
    "allwk_sumv1.plot(ax=ax,label='without chemical records');\n",
    "ax.legend();\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(hndl.browser_states_dir,state_file_handle,'number_disc_in_state.jpg'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6556c947-2397-49aa-8423-04fb4940f6ab",
   "metadata": {},
   "source": [
    "---\n",
    "## Water use\n",
    "### Gallons used, recorded as TotalBaseWaterVolume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87b5de8-4195-4827-8589-8666aabd6d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdf = alldf.groupby('DisclosureId',as_index=False)[['date','TotalBaseWaterVolume','APINumber','bgStateName']].first()\n",
    "wdf = wdf[wdf.date.dt.year>2010]\n",
    "gb1 = wdf.groupby('date')['TotalBaseWaterVolume'].median()\n",
    "# gb1 = gb1/1000000\n",
    "allwk_tbwv = gb1.resample(\"M\").median()\n",
    "# don't show the final two months because it is often wonky because it is not full data\n",
    "ax = allwk_tbwv.iloc[:-2].plot(figsize=(7,5), ylabel='Median gallons of water\\n each month',style='o',xlabel='');\n",
    "ax.set_title(f'Typical quantity of water used in {statename.title()}',fontsize=14);\n",
    "ax.tick_params(axis=\"y\", labelsize=13)\n",
    "ax.tick_params(axis=\"x\", labelsize=13)\n",
    "plt.ylabel('Median water use per month\\n (gallons)',fontsize=13);\n",
    "ax = gca().yaxis.set_major_formatter(mpl.ticker.StrMethodFormatter('{x:,.0f}'))\n",
    "plt.tight_layout()\n",
    "# plt.savefig(os.path.join(hndl.blog_im_dir,'median_water_used.jpg'),dpi=150)\n",
    "plt.savefig(os.path.join(hndl.browser_states_dir,state_file_handle,'water_use_in_state.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23595dbc-47c1-45e7-847e-8742ca82b139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see if we should build water source plot\n",
    "gb = alldf.groupby('DisclosureId',as_index=False)[['TotalBaseWaterVolume','ws_perc_total','bgStateName',\n",
    "                                                   'perc_pw','perc_gw_high_TDS','perc_gw_low_TDS','date',\n",
    "                                                   'perc_sw_high_TDS','perc_sw_low_TDS',\n",
    "                                                   'perc_other_high_TDS','perc_other_low_TDS']].first()\n",
    "\n",
    "\n",
    "ws_start = datetime.datetime(year=2023,month=12,day=1)\n",
    "c1 = gb.ws_perc_total>0\n",
    "c2 = gb.ws_perc_total==100\n",
    "c3 = gb.date>=ws_start\n",
    "num_ws_disc = len(gb[c1])\n",
    "\n",
    "# all_disc = len(gb)\n",
    "all_disc_since_start = len(gb[c3])\n",
    "frac_ws_disc = num_ws_disc/all_disc_since_start\n",
    "\n",
    "\n",
    "if num_ws_disc >5:\n",
    "    display(md(f'### Reported (optional) water source'))\n",
    "    display(md(\"\"\"In late 2023, [FracFocus added an option](https://fracfocus.org/news/water-source-data) for companies to report the type of water source(s)\n",
    "    they used in the fracking job. Because this reporting is\n",
    "    optional, this figure represent only a fraction of the disclosure published since its introduction.\n",
    "    The categories available are: \"\"\"))\n",
    "    display(md(\"\"\">##### Ground water, Surface water, Produced water, and Other.\"\"\"))\n",
    "    display(md(\"\"\"Additionally, ground, surface and other are categorized by low or high \"total dissolved solids\" (TDS).  We don't display those distinctions here. \"\"\"))\n",
    "    \n",
    "    gb['perc_gw'] = gb.perc_gw_low_TDS + gb.perc_gw_high_TDS  \n",
    "    gb['perc_sw'] = gb.perc_sw_low_TDS + gb.perc_sw_high_TDS  \n",
    "    gb['perc_other'] = gb.perc_other_low_TDS + gb.perc_other_high_TDS  \n",
    "\n",
    "    gb['vol_gw'] = gb.perc_gw * gb.TotalBaseWaterVolume /100\n",
    "    gb['vol_sw'] = gb.perc_sw * gb.TotalBaseWaterVolume /100\n",
    "    gb['vol_pw'] = gb.perc_pw * gb.TotalBaseWaterVolume /100\n",
    "    gb['vol_other'] = gb.perc_other * gb.TotalBaseWaterVolume /100    \n",
    "    num_disc = len(gb[c1])\n",
    "\n",
    "    out = gb.groupby('bgStateName',as_index=False)[['vol_gw','vol_sw','vol_pw','vol_other']].sum()\n",
    "    out = out.drop('bgStateName',axis=1)\n",
    "    meltdf = out.melt()\n",
    "    ax = meltdf.plot(kind='bar',legend=False)\n",
    "    plt.suptitle(f'Reported water source for {num_disc} {statename.title()} fracking jobs')\n",
    "    plt.title(f'(data from about {round(frac_ws_disc,3):.0%} of disclosures since Dec. 2023)',fontsize=10)\n",
    "    plt.xlabel('Reported water source')\n",
    "    plt.ylabel('Total Gallons')\n",
    "    ax.set_xticklabels(['Ground\\nWater','Surface\\nWater','Produced\\nWater','Other'])\n",
    "    plt.xticks(rotation=0)  # Rotate x-axis labels if needed\n",
    "    ax = gca().yaxis.set_major_formatter(mpl.ticker.StrMethodFormatter('{x:,.0f}'));\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(hndl.browser_states_dir,state_file_handle,'water_source_in_state.jpg'))    \n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16ec1a1-a77f-44aa-b6a5-12ecae9409de",
   "metadata": {},
   "source": [
    "<a id='counties'></a>\n",
    "---\n",
    "## County-based details\n",
    "\n",
    "Click on the county name in the table to view a county summary page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68d9482-8289-4bc4-9298-09289e4c1ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CountyCntTable(alldf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9c8432-4de4-4a59-ad13-6889452d1921",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(md(\"--- \\n # Trade Secret designations\"))\n",
    "testtitle = statename.title() +': Trade Secret frequency'\n",
    "# print(alldf.columns)\n",
    "statelab = statename.replace(' ','_')\n",
    "outfn = os.path.join(hndl.browser_states_dir,statelab,'state_proprietary_plot.jpg')\n",
    "c_plots.proprietary_bars(alldf,testtitle,save_file=outfn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ecbf70-cd17-42ba-a016-788864b9ac1d",
   "metadata": {},
   "source": [
    "<a id='operators'></a>\n",
    "---\n",
    "## Who are the Operators in this state?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c65d62-fb36-4a1e-8eaf-d4c59fd9c3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ogb = alldf.groupby(['bgOperatorName','DisclosureId'],as_index=False).size()\n",
    "ogbname = alldf.groupby(['bgOperatorName'])['OperatorName'].agg(lambda x: x.value_counts().index[0])\n",
    "ogbname = ogbname.reset_index()\n",
    "mg = pd.merge(ogb,ogbname,on='bgOperatorName',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e03616-a021-4910-85f2-6460f06b7b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = mg.OperatorName.value_counts()[:15].plot.barh(figsize=(8,5))\n",
    "ax.set_title(f'Top Operators in {statename.title()}')\n",
    "ax.set_xlabel('Number of disclosures in FracFocus');\n",
    "plt.tight_layout();\n",
    "plt.savefig(os.path.join(hndl.browser_states_dir,state_file_handle,'state_major_operators.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1991f1-805c-4a31-99e2-8146fbe43652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_water(row):\n",
    "    s = str(th.round_sig(row.TotalBaseWaterVolume,3))\n",
    "    s += '<br>'\n",
    "    s += str(th.round_sig(row.TBWV90,3))\n",
    "    return s\n",
    "\n",
    "alldf['year'] = alldf.date.dt.year.astype(str)\n",
    "gbOp = alldf.groupby(['DisclosureId','bgCountyName','bgOperatorName','year'],as_index=False)['TotalBaseWaterVolume'].first()\n",
    "gbOp.bgCountyName = gbOp.bgCountyName.str.title()\n",
    "\n",
    "gbOp1 = gbOp.groupby('bgOperatorName',as_index=False)['DisclosureId'].count().rename({'DisclosureId':'num_fracks'},axis=1)\n",
    "\n",
    "gbOp2 = gbOp.groupby(['bgOperatorName','year'],as_index=False)['DisclosureId'].count()\n",
    "gbOp2['year_cnt'] = gbOp2.year + '(' + gbOp2.DisclosureId.astype(str) + ')'\n",
    "\n",
    "gbOpY = gbOp2.groupby('bgOperatorName')['year_cnt'].apply(set).reset_index()\n",
    "gbOpY['years'] = gbOpY.year_cnt.map(lambda x: th.xlate_to_str(x,sep='<br>'))\n",
    "\n",
    "gbOp3 = gbOp.groupby(['bgOperatorName','bgCountyName'],as_index=False)['DisclosureId'].count()\n",
    "gbOp3['counties_cnt'] = gbOp3.bgCountyName + '(' + gbOp3.DisclosureId.astype(str) + ')'\n",
    "\n",
    "gbOp4 = gbOp3.groupby('bgOperatorName')['counties_cnt'].apply(set).reset_index()\n",
    "gbOp4['counties'] = gbOp4.counties_cnt.map(lambda x: th.xlate_to_str(x,sep='<br>'))\n",
    "\n",
    "# gbOp5 = df.groupby('bgOperatorName')['OperatorName'].agg(lambda x: x.value_counts().index[0])\n",
    "gbOp5 = alldf.groupby('bgOperatorName')['OperatorName'].apply(set).reset_index()\n",
    "gbOp5['names'] = gbOp5.OperatorName.map(lambda x: th.xlate_to_str(x,sep='<br>'))\n",
    "# gbOp5.names = gbOp5.names + '<br>[' + gbOp5.bgOperatorName + ']'\n",
    "\n",
    "gbOp6 = gbOp.groupby('bgOperatorName',as_index=False)['TotalBaseWaterVolume'].median()\n",
    "gbOp6.rename({'TotalBaseWaterVolume':'Water,\\nmedian (gal)'},axis=1,inplace=True)\n",
    "# gbOp7 = gbOp.groupby('bgOperatorName',as_index=False)['TotalBaseWaterVolume'].agg(lambda x: np.percentile(x,90))\n",
    "gbOp7 = gbOp.groupby('bgOperatorName',as_index=False)['TotalBaseWaterVolume'].max()\n",
    "gbOp7.rename({'TotalBaseWaterVolume':'Water,\\nmax (gal)'},axis=1,inplace=True)\n",
    "mg = pd.merge(gbOp6,gbOp7,on='bgOperatorName')\n",
    "# mg.fillna(0,inplace=True)\n",
    "# mg['TBWV'] = mg.apply(lambda x: make_water(x),axis=1)\n",
    "mg = pd.merge(mg,gbOp1,on='bgOperatorName')\n",
    "mg = pd.merge(mg,gbOpY,on='bgOperatorName')\n",
    "mg = pd.merge(mg,gbOp4[['bgOperatorName','counties']],on='bgOperatorName')\n",
    "mg = pd.merge(mg,gbOp5,on='bgOperatorName').sort_values('num_fracks',ascending=False)\n",
    "\n",
    "mg['link'] = mg.bgOperatorName.map(lambda x: th.getOpLink(x,x,up_level=True))\n",
    "# mg.names = mg.names + '<br>[' + mg.link + ']'\n",
    "mg.names = '<center><h3>'+mg.names+'<br><br>'+mg.link+'</h3></center>'\n",
    "\n",
    "iShow(mg[['names','num_fracks','years','counties','Water,\\nmedian (gal)','Water,\\nmax (gal)']].reset_index(drop=True),\n",
    "      maxBytes=0,columnDefs=[{\"width\": \"150px\", \"targets\": 0}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c944a6f4-9bc5-4f26-b4e4-96a9b1db66da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8fd5ffde-8b31-4593-8a7c-ab1c47bbc16c",
   "metadata": {},
   "source": [
    "<a id='duplicates'></a>\n",
    "# Duplicate records\n",
    "As of Aug. 2024, the disclosures of many operator companies had **[apparently unintentional duplicate records](https://open-ff.org/2024/09/17/fracfocus-duplicate-records/)** in them.  Such duplicates can distort calculations of chemical quantity.  In this section, we compare the current status of those records **for this state** with the baseline taken in Aug. 2024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bd5542-1dc2-4e24-b140-14aa097baba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "fn = os.path.join(r\"G:\\My Drive\\webshare\\daily_status\",'dup_rec_baseline.parquet')\n",
    "baseline = pd.read_parquet(fn)\n",
    "bl = baseline[baseline.bgStateName==statename].copy()\n",
    "# print(bl.columns)\n",
    "blapis = bl.APINumber.unique().tolist()\n",
    "\n",
    "if len(bl)==0:\n",
    "    display(md('## No duplicates found in baseline (August 2024)'))\n",
    "else:\n",
    "    display(md('### Baseline summary (Aug. 2024)'))\n",
    "    gb = bl.groupby(['bgStateName'],as_index=False).size().rename({'size':'num disclosures'},axis=1)\n",
    "    gb1 = bl.groupby(['bgStateName'],as_index=False).mass.sum()\n",
    "    mg = pd.merge(gb,gb1,on = 'bgStateName',how='left')\n",
    "    mg['mean mass per disclosure'] = round(mg.mass/mg['num disclosures'])\n",
    "    mg = mg.rename({'mass':'mass of all duplicates (pounds)'},axis=1)\n",
    "    display(mg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844f45ce-fd1f-4037-b440-21c85e6ecdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "unfiltdf = pd.read_parquet(os.path.join(hndl.sandbox_dir,'state_unfilt.parquet'))\n",
    "c = unfiltdf.dup_rec\n",
    "new = unfiltdf[c].copy()\n",
    "if len(new)==0:\n",
    "    display(md('## No duplicates found in current data set'))\n",
    "else:\n",
    "    display(md('---\\n ### Current summary'))\n",
    "    # look for removed apis\n",
    "    newapis = new.APINumber.unique().tolist()\n",
    "    allapis = alldf.APINumber.unique().tolist()\n",
    "    removed = []\n",
    "    corrected = []\n",
    "    for api in blapis:\n",
    "        if not api in newapis:\n",
    "            if api in allapis:\n",
    "                corrected.append(api)\n",
    "            else:\n",
    "                removed.append(api)\n",
    "    display(md(f'Baseline disclosures with duplicates **REMOVED** from FracFocus: {len(removed)}'))   \n",
    "    display(md(f'Baseline disclosures with duplicates **CORRECTED** in FracFocus: {len(corrected)}'))   \n",
    "\n",
    "    gb = new.groupby(['bgStateName','DisclosureId'],as_index=False).size()\n",
    "    gb1 = new.groupby(['bgStateName','DisclosureId'],as_index=False).mass.sum()\n",
    "    mg = pd.merge(gb,gb1,on=['bgStateName','DisclosureId'], how='left')\n",
    "\n",
    "    sgb = mg.groupby(['bgStateName'],as_index=False).size().rename({'size':'num disclosures'},axis=1)\n",
    "    sgb1 = mg.groupby(['bgStateName'],as_index=False).mass.sum()\n",
    "    smg = pd.merge(sgb,sgb1,on = 'bgStateName',how='left')\n",
    "    smg['mean mass per disclosure'] = round(smg.mass/smg['num disclosures'])\n",
    "    smg = smg.rename({'mass':'mass of all duplicates (pounds)'},axis=1)\n",
    "    iShow(smg)\n",
    "    display(md('---'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2f6f43-c373-4ef8-b37d-bdc68b776ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(new)>0:   \n",
    "    display(md('---\\n### List of disclosures with duplicates\\n\\n'))\n",
    "    gbsize = new.groupby(['DisclosureId'],as_index=False).size().rename({'size':'numdups'},axis=1)\n",
    "    gbmain = new.groupby(['DisclosureId'],as_index=False)[['OperatorName','APINumber','date',\n",
    "                                                           'bgStateName','bgCountyName']].first()\n",
    "    lmg = pd.merge(gbmain,gbsize,on='DisclosureId',how='left')\n",
    "    lmg['FF_disc'] = lmg.apply(lambda x: th.getFFLink(x,fmt='short'),axis=1)\n",
    "    lmg.bgStateName = lmg.bgStateName.str.title()\n",
    "    lmg.bgCountyName = lmg.bgCountyName.str.title()\n",
    "    out = lmg[['FF_disc','date','numdups','bgStateName','bgCountyName','OperatorName']]\n",
    "    out.columns = ['API Number<br> (and link)','date','Number of<br>duplicate<br>records','State','County','Operator']\n",
    "    display(out)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999d920a-679d-45cb-8ee0-971fb783e136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # wells_in_dist_fn = 'FFwells_in_school_districts.csv'\n",
    "# distFF = pd.read_csv(wells_in_dist_fn)\n",
    "# distFF = distFF[distFF.bgStateName==statename]\n",
    "# distFF.num_FF_wells.fillna(0,inplace=True)\n",
    "# iShow(distFF[['NAME','GEOID','num_FF_wells','num_all_wells']].reset_index(drop=True),\n",
    "#      classes=\"display compact cell-border\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3103a3ce-ecf1-4376-a9ff-d5abfd6b91c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34c42b9-aae0-4070-84cd-cfaa6055091e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
