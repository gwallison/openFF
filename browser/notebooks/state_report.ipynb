{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9c7fc4-03cf-493c-839f-2406769e7b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'c:/MyDocs/integrated/') # adjust to your setup\n",
    "\n",
    "%run \"catalog_support.py\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68199e2-8615-4b62-ae24-56d2bf5602a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alldf = pd.read_csv('state.csv',low_memory=False)\n",
    "alldf = pd.read_parquet(os.path.join(hndl.sandbox_dir,'state.parquet'))\n",
    "alldf.date = pd.to_datetime(alldf.date)\n",
    "statename = alldf.bgStateName.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f56f1bc-d03d-42b0-864e-00d2080876f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print( th.getMoleculeImg(cas,size=300))\n",
    "showHeader(statename.title(), link_up_level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a5cf5c-9ee6-4cee-bbec-830a875e1307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xlate_val(n):\n",
    "    if n==0:\n",
    "        return ''\n",
    "    if n<1000:\n",
    "        return round_sig(n,1)\n",
    "    x = round_sig(n,1)\n",
    "    return x[0]+ 'k'\n",
    "\n",
    "def make_annot(gb):\n",
    "    annot = gb.copy()\n",
    "    annot.DisclosureId = annot.DisclosureId.map(lambda x: xlate_val(x))\n",
    "    #print(annot)\n",
    "    piv = annot.pivot(index='County',columns='year',values='DisclosureId')\n",
    "    piv.fillna('',inplace=True)\n",
    "    #print(piv)\n",
    "    return piv\n",
    "\n",
    "def get_state_center(state):\n",
    "    t = pd.read_csv(r\"C:\\MyDocs\\OpenFF\\src\\openFF-catalog\\work\\state_coords.csv\",\n",
    "                   dtype={'Latitude':'float', 'Longitude':'float'})\n",
    "    t = t[t.state==state]\n",
    "    #print(t)\n",
    "    return [t.Latitude.mean(),t.Longitude.mean()*-1]\n",
    "\n",
    "    \n",
    "def CountyMap(df):\n",
    "    start_loc = get_state_center(statename)\n",
    "    #print(statename,start_loc)\n",
    "    cond = ~df.location_error\n",
    "    if cond.sum()==0:  # no valid fracks for this state\n",
    "        display(md(f'### No mappable fracks for {statename}!'))\n",
    "        display(md(f'This is usually caused when \"CountyName\" in FracFocus dont match standard names'))\n",
    "        return\n",
    "    gb = df[cond].groupby(['bgStateName','bgCountyName',\n",
    "                                                   'DisclosureId'],as_index=False).size()\n",
    "    gb = gb.groupby(['bgStateName','bgCountyName'],as_index=False)['DisclosureId'].count().rename({'bgStateName':'StateName',\n",
    "                                                                                                'bgCountyName':'CountyName',\n",
    "                                                                                                'DisclosureId':'value'},\n",
    "                                                                                                axis=1)\n",
    "    zoom = 6\n",
    "    if statename in ['texas','california']:\n",
    "        zoom = 5\n",
    "    if statename in ['alaska']:\n",
    "        zoom = 4\n",
    "        \n",
    "    mapping.create_county_choropleth(gb,plotlog=True,custom_scale= [0,1,2,3,4,5],\n",
    "                             start_loc=start_loc, # center of state's data\n",
    "                             legend_name='Number of FracFocus disclosures',\n",
    "                             start_zoom=zoom,fields=['StateName','CountyName','orig_value'],\n",
    "                             aliases=['State: ','County: ','Number Fracking disclosures: '])\n",
    "\n",
    "def CountyCntTable(df):\n",
    "    # first, make the general searchable table\n",
    "    gb = df.groupby(['bgCountyName','DisclosureId'],as_index=False)['date'].first()\n",
    "    gb['year'] = gb.date.dt.year.astype('str')\n",
    "    gb1 = gb.groupby(['bgCountyName'],as_index=False)['DisclosureId'].count().rename({'DisclosureId':'disclosure_count'},\n",
    "                                                                                  axis=1)\n",
    "    gb2 = gb1.copy()\n",
    "    gbop = df.groupby('bgCountyName')['OperatorName'].agg(lambda x:x.value_counts().index[0:4]).reset_index()\n",
    "    gbop.OperatorName = gbop.OperatorName.map(lambda x: th.xlate_to_str(x,'; ',sort=False))\n",
    "    gbop = gbop.rename({'OperatorName':'Top Operators'},axis=1)\n",
    "    gb2 = pd.merge(gb2,gbop,on='bgCountyName',how='left')\n",
    "\n",
    "#     gbprop = df[df.bgCAS=='proprietary'].groupby('bgCountyName',as_index=False).size()\n",
    "# #     gbprop.bgCAS.fillna(0,inplace=True)\n",
    "#     gbprop = gbprop.rename({'size':'Trade Secret records'},axis=1)\n",
    "#     gb2 = pd.merge(gb2,gbprop,on='bgCountyName',how='left')\n",
    "#     gb2['Trade Secret records'].fillna(0,inplace=True)\n",
    "    \n",
    "    gbtbwv = df.groupby(['bgCountyName','DisclosureId'],as_index=False)['TotalBaseWaterVolume'].first()\n",
    "    gbtbwv = gbtbwv.groupby('bgCountyName',as_index=False)['TotalBaseWaterVolume'].sum().rename({'TotalBaseWaterVolume':'tot_gallons_water'},\n",
    "                                                                                                axis=1)\n",
    "    gbtbwv.tot_gallons_water = gbtbwv.tot_gallons_water.map(lambda x: th.round_sig(x,3))\n",
    "    gb2 = pd.merge(gb2,gbtbwv,on='bgCountyName',how='left')\n",
    "\n",
    "    #print(gb2.head())\n",
    "    gb2['County'] = '<center><h4>'+gb2.bgCountyName.str.title().map(lambda x: th.getCountyLink(x,statename,x))+'</h4></center>'\n",
    "    gb2 = gb2.drop('bgCountyName',axis=1)\n",
    "    iShow(gb2.sort_values('disclosure_count',ascending=False)[['County','disclosure_count',\n",
    "                                                               #'Trade Secret records'\n",
    "                                                               'tot_gallons_water',\n",
    "                                                               'Top Operators']].reset_index(drop=True),\n",
    "         classes=\"display compact cell-border\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910bdd39-6067-48f9-8374-93ad27b197c4",
   "metadata": {},
   "source": [
    "# Where are the fracking locations in this state?\n",
    "This is not an exhaustive set of wells in these counties; it is only those wells for which the operating company submits a chemical disclosure to FracFocus.  In addition, this map omits disclosures for which location information is conflicting, such as the Latitude/Longitude values are outside of the reported county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3860db3-6c4d-4dea-9e64-38efc5776d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "CountyMap(alldf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16ec1a1-a77f-44aa-b6a5-12ecae9409de",
   "metadata": {},
   "source": [
    "---\n",
    "## County-based details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68d9482-8289-4bc4-9298-09289e4c1ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CountyCntTable(alldf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ecbf70-cd17-42ba-a016-788864b9ac1d",
   "metadata": {},
   "source": [
    "---\n",
    "## Who are the Operators in this state?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1991f1-805c-4a31-99e2-8146fbe43652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_water(row):\n",
    "    s = str(th.round_sig(row.TotalBaseWaterVolume,3))\n",
    "    s += '<br>'\n",
    "    s += str(th.round_sig(row.TBWV90,3))\n",
    "    return s\n",
    "\n",
    "alldf['year'] = alldf.date.dt.year.astype(str)\n",
    "gbOp = alldf.groupby(['DisclosureId','bgCountyName','bgOperatorName','year'],as_index=False)['TotalBaseWaterVolume'].first()\n",
    "gbOp.bgCountyName = gbOp.bgCountyName.str.title()\n",
    "\n",
    "gbOp1 = gbOp.groupby('bgOperatorName',as_index=False)['DisclosureId'].count().rename({'DisclosureId':'num_fracks'},axis=1)\n",
    "\n",
    "gbOp2 = gbOp.groupby(['bgOperatorName','year'],as_index=False)['DisclosureId'].count()\n",
    "gbOp2['year_cnt'] = gbOp2.year + '(' + gbOp2.DisclosureId.astype(str) + ')'\n",
    "\n",
    "gbOpY = gbOp2.groupby('bgOperatorName')['year_cnt'].apply(set).reset_index()\n",
    "gbOpY['years'] = gbOpY.year_cnt.map(lambda x: th.xlate_to_str(x,sep='<br>'))\n",
    "\n",
    "gbOp3 = gbOp.groupby(['bgOperatorName','bgCountyName'],as_index=False)['DisclosureId'].count()\n",
    "gbOp3['counties_cnt'] = gbOp3.bgCountyName + '(' + gbOp3.DisclosureId.astype(str) + ')'\n",
    "\n",
    "gbOp4 = gbOp3.groupby('bgOperatorName')['counties_cnt'].apply(set).reset_index()\n",
    "gbOp4['counties'] = gbOp4.counties_cnt.map(lambda x: th.xlate_to_str(x,sep='<br>'))\n",
    "\n",
    "# gbOp5 = df.groupby('bgOperatorName')['OperatorName'].agg(lambda x: x.value_counts().index[0])\n",
    "gbOp5 = alldf.groupby('bgOperatorName')['OperatorName'].apply(set).reset_index()\n",
    "gbOp5['names'] = gbOp5.OperatorName.map(lambda x: th.xlate_to_str(x,sep='<br>'))\n",
    "# gbOp5.names = gbOp5.names + '<br>[' + gbOp5.bgOperatorName + ']'\n",
    "\n",
    "gbOp6 = gbOp.groupby('bgOperatorName',as_index=False)['TotalBaseWaterVolume'].median()\n",
    "gbOp6.rename({'TotalBaseWaterVolume':'Water,\\nmedian (gal)'},axis=1,inplace=True)\n",
    "# gbOp7 = gbOp.groupby('bgOperatorName',as_index=False)['TotalBaseWaterVolume'].agg(lambda x: np.percentile(x,90))\n",
    "gbOp7 = gbOp.groupby('bgOperatorName',as_index=False)['TotalBaseWaterVolume'].max()\n",
    "gbOp7.rename({'TotalBaseWaterVolume':'Water,\\nmax (gal)'},axis=1,inplace=True)\n",
    "mg = pd.merge(gbOp6,gbOp7,on='bgOperatorName')\n",
    "# mg.fillna(0,inplace=True)\n",
    "# mg['TBWV'] = mg.apply(lambda x: make_water(x),axis=1)\n",
    "mg = pd.merge(mg,gbOp1,on='bgOperatorName')\n",
    "mg = pd.merge(mg,gbOpY,on='bgOperatorName')\n",
    "mg = pd.merge(mg,gbOp4[['bgOperatorName','counties']],on='bgOperatorName')\n",
    "mg = pd.merge(mg,gbOp5,on='bgOperatorName').sort_values('num_fracks',ascending=False)\n",
    "\n",
    "mg['link'] = mg.bgOperatorName.map(lambda x: th.getOpLink(x,x))\n",
    "mg.names = mg.names + '<br>[' + mg.link + ']'\n",
    "\n",
    "iShow(mg[['names','num_fracks','years','counties','Water,\\nmedian (gal)','Water,\\nmax (gal)']].reset_index(drop=True),\n",
    "      maxBytes=0,columnDefs=[{\"width\": \"150px\", \"targets\": 0}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c77391-8278-4afe-985f-312197ce47df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib.offsetbox import AnchoredText\n",
    "\n",
    "# def proprietary_plot(df,plot_title='TEST',minyr=2011,maxyr=2021):\n",
    "#     df = df.copy()\n",
    "#     df['year'] = df.date.dt.year\n",
    "#     df = df[df.year<=maxyr]\n",
    "#     df = df[df.year>=minyr]\n",
    "#     prop = df.is_proprietary\n",
    "#     gb = df[prop].groupby('DisclosureId',as_index=False)['bgCAS'].count().rename({'bgCAS':'numprop'},axis=1)\n",
    "#     gb1 = df[df.is_valid_cas].groupby('DisclosureId',as_index=False)['bgCAS'].count().rename({'bgCAS':'numvalid'},axis=1)\n",
    "#     gb2 = df.groupby('DisclosureId',as_index=False)['date'].first()\n",
    "#     mg = pd.merge(gb2,gb,on='DisclosureId',how='left')\n",
    "#     mg = pd.merge(mg,gb1,on='DisclosureId',how='left')\n",
    "#     mg.fillna(0,inplace=True) # there will be disclosures with 0 proprietary; need to fill\n",
    "#     mg['percProp'] = (mg.numprop / mg.numvalid) * 100\n",
    "\n",
    "#     mg['propCut'] = pd.cut(mg.percProp,right=False,bins=[0,0.0001,10,25,50,101],\n",
    "#                           labels=['no proprietary claims','up to 10% proprietary claims',\n",
    "#                                   'between 10 and 25% proprietary claims',\n",
    "#                                   'between 25 and 50% proprietary claims',\n",
    "#                                   'greater than 50% proprietary claims'])\n",
    "#     mg['year'] = mg.date.dt.year\n",
    "#     out = mg.drop(['date','DisclosureId'],axis=1)\n",
    "#     t = out[out.numvalid>0].groupby(['year','propCut'],as_index=False)['numvalid'].count()\n",
    "#     sums = t.groupby('year',as_index=False)['numvalid'].sum().rename({'numvalid':'tot'},axis=1)\n",
    "#     t = pd.merge(t,sums,on='year',how='left')\n",
    "#     t['PercentProp'] = t.numvalid/t.tot *100\n",
    "\n",
    "#     piv = t.pivot(index='year', columns='propCut', values='PercentProp')\n",
    "\n",
    "#     ax = piv.plot.area(figsize=(12,7),ylim=(0,100),xlim=(minyr,maxyr),colormap='Reds')\n",
    "#     ax.set_title(f'Percentage of valid records that are Trade Secret claims at the disclosure level', fontsize=16)\n",
    "#     handles, labels = ax.get_legend_handles_labels()\n",
    "#     ax.legend(handles[::-1], labels[::-1], title='Disclosure Proprietary\\nPercentage class\\n',\n",
    "#               loc='upper left',bbox_to_anchor=(1, 1))\n",
    "#     ax.set_ylabel('Percentage of disclosures', fontsize=16)\n",
    "#     ax.set_xlabel('Year', fontsize=16)\n",
    "#     plt.xticks(fontsize=14)\n",
    "#     plt.yticks(fontsize=14)\n",
    "#     plt.suptitle(f'{plot_title}',fontsize=24)\n",
    "\n",
    "#     gb = df.groupby(['year','DisclosureId'],as_index=False)['bgCAS'].count()\n",
    "#     gb = gb.groupby('year',as_index=False)['DisclosureId'].count()#.rename({'DisclosureId':'number of disclosures'},axis=1)\n",
    "#     s = 'Number of disclosures by year:\\n\\n'\n",
    "#     for i,row in gb.iterrows():\n",
    "#         s+= f'   {row.year}: {row.DisclosureId:7,} \\n'\n",
    "#     at2 = AnchoredText(s,\n",
    "#                        loc='lower left', prop=dict(size=10), frameon=False,\n",
    "#                        bbox_to_anchor=(1., 0.),\n",
    "#                        bbox_transform=ax.transAxes\n",
    "#                        )\n",
    "#     at2.patch.set_boxstyle(\"square,pad=0.\")\n",
    "#     ax.add_artist(at2)\n",
    "\n",
    "    \n",
    "# # test = 'pennsylvania'\n",
    "# # variable = 'bgStateName'\n",
    "# testtitle = statename.title() +': Trade Secret frequency'\n",
    "# if len(alldf.DisclosureId.unique())>500:\n",
    "#     # small-number states look silly with this plot\n",
    "#     proprietary_plot(alldf,testtitle,minyr=2011,maxyr=alldf.date.dt.year.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999d920a-679d-45cb-8ee0-971fb783e136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # wells_in_dist_fn = 'FFwells_in_school_districts.csv'\n",
    "# distFF = pd.read_csv(wells_in_dist_fn)\n",
    "# distFF = distFF[distFF.bgStateName==statename]\n",
    "# distFF.num_FF_wells.fillna(0,inplace=True)\n",
    "# iShow(distFF[['NAME','GEOID','num_FF_wells','num_all_wells']].reset_index(drop=True),\n",
    "#      classes=\"display compact cell-border\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
