{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0d859c-73a4-4334-9eda-2150da065749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9783b434-731f-438d-bf53-e09a653af90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'c:/MyDocs/integrated/') # adjust to your setup\n",
    "\n",
    "%run \"catalog_support.py\" \n",
    "\n",
    "showHeader('ECMC Disclosure Dashboard',line2=f'(Drilling and) Fracking Chemicals',use_remote=True)\n",
    "import itables.options as opt\n",
    "opt.order = []  # no sorting\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "from IPython.display import Markdown as md\n",
    "\n",
    "# iShow(gb.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa020319-fce9-4eb8-8314-20c7e3fdc495",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make ECMC version of raw_df for disclosure puposes\n",
    "\n",
    "law_begins = datetime.datetime(year=2023,month=7,day=31)\n",
    "\n",
    "########################\n",
    "analysis_date = datetime.datetime(year=2025,month=4,day=7)\n",
    "########################\n",
    "deadline_days = datetime.timedelta(days=150)\n",
    "\n",
    "archive_folder = r\"C:\\MyDocs\\integrated\\openFF_archive\\raw_dataframes\" # production machine\n",
    "alst = os.listdir(archive_folder)\n",
    "alst.sort()\n",
    "print(f'Using file: {alst[-1]}')\n",
    "ffdf = pd.read_parquet(os.path.join(archive_folder,alst[-1]),  # gets the most recent raw_data\n",
    "                      columns=['APINumber','StateName','JobStartDate','JobEndDate','OperatorName','DisclosureId'],\n",
    "                      filters = [('StateName','==','Colorado')] )\n",
    "ffdf['start_date'] = pd.to_datetime(ffdf.JobStartDate,errors='coerce',format=\"%m/%d/%Y %I:%M:%S %p\")\n",
    "ffdf['end_date'] = pd.to_datetime(ffdf.JobEndDate,errors='coerce',format=\"%m/%d/%Y %I:%M:%S %p\")\n",
    "ffdf = ffdf[ffdf.end_date>law_begins]  # filter to within law's effect\n",
    "ffdf.end_date = ffdf.end_date.dt.date\n",
    "ffdf.start_date = ffdf.start_date.dt.date\n",
    "ffdf['api10'] = ffdf.APINumber.str[:10]\n",
    "FFapis = ffdf.api10.unique().tolist()\n",
    "\n",
    "gb0 = ffdf.groupby(['DisclosureId','api10'],as_index=False)[['start_date','end_date','OperatorName']].first()\n",
    "gb1 = gb0.groupby('api10',as_index=False).size().rename({'size':'num_FF_disclosures'},axis=1)\n",
    "gb2 = gb0.groupby('api10',as_index=False)[['start_date','end_date','OperatorName']].first()\n",
    "gbff = gb1.merge(gb2,on='api10',how='left')\n",
    "# gbff[['api10','start_date','end_date','OperatorName']].sort_values('end_date')\n",
    "print(f'Number of FF disclosures: {len(gbff)}')\n",
    "print(f'Earliest start date: {gbff.start_date.min()}')\n",
    "print(f'Latest end date: {gbff.end_date.max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e455680f-f127-46be-b924-29a3451866cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get new well data set\n",
    "import scrape.Colorado.CO_data_helper as cdh\n",
    "wells_df = cdh.fetch_full_wells_df()\n",
    "\n",
    "# sort by spud, so most recent spud is kept if there are duplicates\n",
    "wells_df = wells_df.sort_values('spud')\n",
    "# drop well_df duplicates\n",
    "wells_df = wells_df[~wells_df.api10.duplicated(keep='last')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684a286d-0c04-40f8-a66e-91479fc3dcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get locationID into FF data\n",
    "\n",
    "mg = pd.merge(gbff,wells_df[['api10','location','Operator','spud']],on='api10',how='left')\n",
    "mg = mg.sort_values('end_date')\n",
    "ffsum = mg.groupby('location',as_index=False)[['spud','Operator','start_date','end_date','OperatorName']].last()\n",
    "gb1 = mg.groupby('location',as_index=False).size().rename({'size':'num_FF_disclosures'},axis=1)\n",
    "mg = ffsum.merge(gb1,on='location',how='left')\n",
    "\n",
    "# mg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8338cb-c0e1-40ae-bd65-317781922233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get current ECMC disclosures and add to table\n",
    "url = \"https://ecmc.state.co.us/depot/Stats/ChemicalDisclosures/Index/Locations\"\n",
    "loc_nb_dir = r\"G:\\My Drive\\Info_home\\Projects\\Project_Homes\\ECMC_new_disclosure_instrument\\location_webpages\"\n",
    "\n",
    "tables = pd.read_html(url)\n",
    "t = tables[0]\n",
    "t.columns = ['location','loc_name','ECMC_last_date']\n",
    "emg = mg.merge(t,on='location',how='outer')\n",
    "emg.num_FF_disclosures = emg.num_FF_disclosures.fillna('no_FF')\n",
    "emg.loc_name = emg.loc_name.fillna('no_ECMC')\n",
    "emg.ECMC_last_date = emg.ECMC_last_date.fillna(' -- ')\n",
    "\n",
    "emg['nblink'] = th.wrap_URL_in_html(\n",
    "locs_with_disc = emg.location.tolist()\n",
    "display(md(f'#### Num locations with no ECMC disclosures: {len(emg[emg.loc_name==\"no_ECMC\"])}'))\n",
    "display(md(f'#### Num locations with no FF disclosures: {len(emg[emg.num_FF_disclosures==\"no_FF\"])}'))\n",
    "emg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfed292-c9ff-4631-af59-d346eceed369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make wells df for recent spuds, not in other table already\n",
    "\n",
    "display(md(\"### Summary for wells with no FF or ECMC disclosure\"))\n",
    "c = wells_df.spud>=law_begins\n",
    "gb1 = wells_df[c].groupby('location',as_index=False)[['spud']].max()\n",
    "gb2 = wells_df[c].groupby('location',as_index=False)[['Operator']].first()\n",
    "gb3 = wells_df[c].groupby('location',as_index=False).size().rename({'size':'num_ECMC_wells'},axis=1)\n",
    "\n",
    "gbwells = pd.merge(gb1,gb2,on='location',how='left')\n",
    "gbwells = gbwells.merge(gb3,on='location',how='left')\n",
    "not_disc =~gbwells.location.isin(locs_with_disc) \n",
    "\n",
    "display(md(f\"#### Total number of wells with spud date but no disclosure: {gbwells.num_ECMC_wells.sum():,}\"))\n",
    "gbwells[not_disc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c573334d-3aee-4e99-afdb-8afbe9433f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(md(\"### Well Operators summary for no FF disclosure\"))\n",
    "display(md(\"For **locations** with no disclosure from either instrument\"))\n",
    "gbwells[not_disc].groupby('Operator',as_index=False)['num_ECMC_wells'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69afeea-f935-4f0f-b102-ce19ab2a6a0e",
   "metadata": {},
   "source": [
    "# Older stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7454044d-b158-4747-9a2e-4916c28756d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Fetch the well database directly from the colorado web page - Gemini generated\n",
    "# ## takes about 30 seconds\n",
    "\n",
    "# import requests\n",
    "# import zipfile\n",
    "# import io\n",
    "# from dbfread import DBF\n",
    "# import pandas as pd\n",
    "# import tempfile\n",
    "# import os\n",
    "\n",
    "# def read_wells_dbf_from_zip(url):\n",
    "#     \"\"\"\n",
    "#     Downloads a zip file, extracts Wells.dbf, and reads it into a pandas DataFrame.\n",
    "\n",
    "#     Args:\n",
    "#         url (str): The URL of the zip file.\n",
    "\n",
    "#     Returns:\n",
    "#         pandas.DataFrame: A DataFrame containing the data from Wells.dbf, or None if an error occurs.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         response = requests.get(url)\n",
    "#         response.raise_for_status()\n",
    "\n",
    "#         with zipfile.ZipFile(io.BytesIO(response.content)) as zip_file:\n",
    "#             dbf_data = zip_file.read(\"Wells.dbf\")\n",
    "\n",
    "#         # Create a temporary file to store the DBF data\n",
    "#         with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n",
    "#             temp_file.write(dbf_data)\n",
    "#             temp_file_path = temp_file.name\n",
    "\n",
    "#         # Read the DBF file from the temporary file path\n",
    "#         dbf = DBF(temp_file_path)\n",
    "#         df = pd.DataFrame(iter(dbf))\n",
    "\n",
    "#         # Delete the temporary file\n",
    "#         os.unlink(temp_file_path)\n",
    "\n",
    "#         return df\n",
    "\n",
    "#     except requests.exceptions.RequestException as e:\n",
    "#         print(f\"Error downloading the file: {e}\")\n",
    "#         return None\n",
    "#     except zipfile.BadZipFile as e:\n",
    "#         print(f\"Error with the zip file: {e}\")\n",
    "#         return None\n",
    "#     except KeyError as e:\n",
    "#         print(f\"Error: 'Wells.dbf' not found in the zip archive. {e}\")\n",
    "#         return None\n",
    "#     except Exception as e:\n",
    "#         print(f\"An unexpected error occurred: {e}\")\n",
    "#         return None\n",
    "\n",
    "# # URL of the zip file\n",
    "# url = \"https://ecmc.state.co.us/documents/data/downloads/gis/WELLS_SHP.ZIP\"\n",
    "\n",
    "# # Read the DBF file into a DataFrame\n",
    "# wells_df = read_wells_dbf_from_zip(url)\n",
    "# # print(wells_df.columns)\n",
    "# if wells_df is not None:\n",
    "#     wells_df['api10'] = wells_df.API_Label.str.replace('-','')\n",
    "#     wells_df['spud'] = pd.to_datetime(wells_df.Spud_Date)\n",
    "#     wells_df['location'] = wells_df.Loc_ID\n",
    "#     wells_df = wells_df[['api10','Operator','spud','location','Facil_Stat']]\n",
    "# else:\n",
    "#     print(\"Failed to read the Wells.dbf file.\")\n",
    "\n",
    "# wells_df = wells_df.sort_values('spud')\n",
    "# wellsgb = wells_df[wells_df.location.notna()].groupby('location',as_index=False)['spud'].last()\n",
    "# gb1 = wells_df[wells_df.location.notna()].groupby('location',as_index=False).size().rename({'size':'num_wells_recs'},axis=1)\n",
    "# wellsgb = wellsgb.merge(gb1,on='location',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b720648-ccd1-4178-befd-3c9b2966c26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wells_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bf87d5-aa8a-43a5-853d-11b61f583f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import datetime\n",
    "\n",
    "# def plot_cumulative_spuds(df, date_column='spud', start_date='2023-08-01'):\n",
    "#     \"\"\"\n",
    "#     Plots the cumulative number of wells spudded over time from a given start date.\n",
    "\n",
    "#     Args:\n",
    "#         df (pd.DataFrame): DataFrame containing spud date information.\n",
    "#         date_column (str): Name of the column containing the spud dates.\n",
    "#         start_date (str): Start date for cumulative calculation (YYYY-MM-DD).\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Convert start_date string to datetime object\n",
    "#     start_date_dt = pd.to_datetime(start_date)\n",
    "\n",
    "#     # Ensure the date column is of datetime type\n",
    "#     df[date_column] = pd.to_datetime(df[date_column])\n",
    "\n",
    "#     # Filter for dates after the start date and today\n",
    "#     c1 = df[date_column] >= start_date_dt\n",
    "#     c2 = df[date_column] < datetime.datetime.today()\n",
    "#     df = df[c1&c2].copy()  # Use .copy() to avoid SettingWithCopyWarning\n",
    "\n",
    "#     # Keep only producing or waiting for completion wells (shut in, abandonded, etc are ignored)\n",
    "#     # c3 = df.Facil_Stat.isin(['PR','WO'])\n",
    "#     # df_filtered = df[c3].copy()\n",
    "#     df_filtered = df.copy()\n",
    "#     # print(f'Wells spudded but excluded by current status: {len(df)-len(df_filtered)}')\n",
    "#     vc = df_filtered.Facil_Stat.value_counts().reset_index()\n",
    "#     status_descriptions = {\n",
    "#         'PR': 'Producing',\n",
    "#         'DG': 'Drilling',\n",
    "#         'PA': 'Plugged and Abandoned',\n",
    "#         'TA': 'Temporarily Abandoned',\n",
    "#         'SI': 'Shut-In',\n",
    "#         'WO': 'Waiting on Completion',\n",
    "#         'AP': 'Active Permit',\n",
    "#         'IJ' : 'Injecting',\n",
    "#         'SO' : 'Suspended Operation'\n",
    "#         # Add other status codes and their descriptions here\n",
    "#     }\n",
    "#     desc = []\n",
    "#     for i,row in vc.iterrows():\n",
    "#         desc.append(status_descriptions[row.Facil_Stat])\n",
    "#     vc[\"Description\"] = desc\n",
    "#      # Print the table\n",
    "#     display(md('# Disclosure of Drilling Chemicals'))\n",
    "#     # display(md(\"## Wells with spud date within law's effect\"))\n",
    "#     display(md('### Current number of wells with discloure of drilling chemicals: 0'))\n",
    "    \n",
    "#     if df_filtered.empty:\n",
    "#         print(\"No spud dates found after the specified start date.\")\n",
    "#         return\n",
    "\n",
    "#     # Daily cumulative plot\n",
    "#     daily_counts = df_filtered.groupby(df_filtered[date_column].dt.date).size().cumsum()\n",
    "    \n",
    "#     plt.figure(figsize=(6,6))\n",
    "#     plt.plot(daily_counts.index, daily_counts.values, marker='o', linestyle='-')\n",
    "#     plt.title('Cumulative number of wells with spud date \\nsince law went into effect')\n",
    "#     plt.xlabel('Spud Date')\n",
    "#     plt.ylabel('Cumulative Number of Wells')\n",
    "#     plt.grid(True)\n",
    "#     plt.xticks(rotation=45)\n",
    " \n",
    "#     # Annotations\n",
    "#     first_day_dt = pd.to_datetime('2023-08-01').date()\n",
    "#     deadline_dt = (pd.to_datetime('2023-08-01') + pd.Timedelta(days=150)).date()\n",
    "\n",
    "#     # Find the y-values for the annotations\n",
    "#     first_day_y = daily_counts.get(first_day_dt, 0)  # Get y-value, default to 0 if not found\n",
    "#     deadline_y = 0 #daily_counts.get(deadline_dt, 0)\n",
    "\n",
    "#     # Annotate the first day\n",
    "#     plt.annotate(\n",
    "#         'July 31, 2023 - Law goes into effect',\n",
    "#         xy=(first_day_dt, first_day_y),\n",
    "#         xytext=(first_day_dt, first_day_y + 700),  # Adjust y-offset as needed\n",
    "#         arrowprops=dict(facecolor='orange', shrink=0.05),\n",
    "#         horizontalalignment='left'\n",
    "#     )\n",
    "\n",
    "#     # Annotate the deadline\n",
    "#     plt.annotate(\n",
    "#         'Deadline for first disclosures\\n (150 days after start of downhole operation)',\n",
    "#         xy=(deadline_dt, 0),\n",
    "#         xytext=(deadline_dt, deadline_y + 50),  # Adjust y-offset as needed\n",
    "#         arrowprops=dict(facecolor='red', shrink=0.05),\n",
    "#         horizontalalignment='left'\n",
    "#     )\n",
    "\n",
    "   \n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "#     return vc, df_filtered\n",
    "\n",
    "# vc, df_filtered = plot_cumulative_spuds(wells_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5f7ea3-c95a-4e65-b941-ecb173e446c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(md(\"\\n\\n### Status codes for wells drilled within law's effect\"))\n",
    "# iShow(vc.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d543a39-f696-4866-be15-204b5efb28cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(md(\"\\n### Operators for wells drilled within law's effect\"))\n",
    "# iShow(df_filtered.Operator.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9a5b4b-f31f-434b-8c15-1a2df6f7d801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### get most recent FF - raw data\n",
    "# import datetime\n",
    "# law_begins = datetime.datetime(year=2023,month=7,day=31)\n",
    "\n",
    "# archive_folder = r\"C:\\MyDocs\\integrated\\openFF_archive\\raw_dataframes\" # production machine\n",
    "# alst = os.listdir(archive_folder)\n",
    "# alst.sort()\n",
    "# ffdf = pd.read_parquet(os.path.join(archive_folder,alst[-1]),  # gets the most recent raw_data\n",
    "#                       columns=['APINumber','StateName','JobStartDate','JobEndDate','OperatorName','DisclosureId'],\n",
    "#                       filters = [('StateName','==','Colorado')] )\n",
    "# ffdf['start_date'] = pd.to_datetime(ffdf.JobStartDate,errors='coerce',format=\"%m/%d/%Y %I:%M:%S %p\")\n",
    "# ffdf['end_date'] = pd.to_datetime(ffdf.JobEndDate,errors='coerce',format=\"%m/%d/%Y %I:%M:%S %p\")\n",
    "# ffdf = ffdf[ffdf.end_date>law_begins]  # filter to within law's effect\n",
    "# ffdf.end_date = ffdf.end_date.dt.date\n",
    "# ffdf['api10'] = ffdf.APINumber.str[:10]\n",
    "# FFapis = ffdf.api10.unique().tolist()\n",
    "\n",
    "# gbff = ffdf.groupby('DisclosureId',as_index=False)[['api10','start_date','end_date','OperatorName']].first()\n",
    "# gb1 = ffdf.groupby('DisclosureId',as_index=False).size().rename({'size':'num_FF_disclosures'},axis=1)\n",
    "# # gbff = gbff.merge(gb1,on='DisclosureId',how='left')\n",
    "# # gbff[['api10','start_date','end_date','OperatorName']].sort_values('end_date')\n",
    "# gbff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d65246b-f760-4741-893d-59c46d1f0826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## get locationID into FF data\n",
    "\n",
    "# mg = pd.merge(gbff,wells_df[['api10','location','spud']],on='api10',how='left')\n",
    "# mg = mg.sort_values('end_date')\n",
    "# ffsum = mg.groupby('location',as_index=False)[['start_date','end_date','OperatorName','spud']].last()\n",
    "# gb1 = mg.groupby('location',as_index=False).size().rename({'size':'num_FF_disclosures'},axis=1)\n",
    "# mg = ffsum.merge(gb1,on='location',how='left')\n",
    "# mg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4bed8f-c9b4-4ff1-80bb-c613fd69009b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## get the ECMC disclosure locations table.\n",
    "# url = \"https://ecmc.state.co.us/depot/Stats/ChemicalDisclosures/Index/Locations\"\n",
    "# t = pd.read_html(url)\n",
    "# # print(len(t))\n",
    "# eLocs = t[0].copy()\n",
    "# eLocs['location'] = eLocs['Location Number']\n",
    "# eLocs['last_update'] = pd.to_datetime(eLocs['Last Disclosure Update'],errors='coerce',format=\"%m/%d/%Y %I:%M:%S %p\")\n",
    "# eLocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d8516f-4b9a-425f-ba47-c93d3b081142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Now fetch each location webpage and the imaged_doc names\n",
    "# # rooturl = 'https://ecmc.state.co.us/depot/Stats/ChemicalDisclosures/Location/'\n",
    "# import scrape.Colorado.CO_imaged_docs_extract as cide\n",
    "# import re\n",
    "\n",
    "# pdf_dir = r\"G:\\My Drive\\webshare\\scrape_data\\Colorado\\imaged_docs\"\n",
    "\n",
    "# outdf = pd.DataFrame()\n",
    "# for i,row in eLocs.iterrows():\n",
    "#     apis = set()\n",
    "\n",
    "#     out = pd.read_html(f\"https://ecmc.state.co.us/depot/Stats/ChemicalDisclosures/Location/{row.location}\")\n",
    "#     file_tab = out[1]\n",
    "#     for j,jrow in file_tab.iterrows():\n",
    "#         docnum = jrow['Document #']\n",
    "#         pdffn = os.path.join(pdf_dir,f'{docnum}.pdf')\n",
    "#         try:\n",
    "#             text = cide.get_pdf_text(pdffn)\n",
    "#             fapis = cide.extract_APINumbers(text)\n",
    "#             for api in fapis:\n",
    "#                 # some apis are misformed. Strip all non-numeric.\n",
    "#                 s = re.sub('[^\\d]','', api)\n",
    "#                 apis.add(s)\n",
    "#         except:\n",
    "#             print(f'Couldnt fetch from location {row.location}, file: {docnum}')\n",
    "#     tmp = pd.DataFrame({'api10':list(apis),'location':row.location,'date':row.last_update})\n",
    "#     outdf = pd.concat([outdf,tmp])\n",
    "# # outdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d943ed22-e395-447f-89c7-a2172e8aef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # lets plot\n",
    "\n",
    "# # FF Daily cumulative plot\n",
    "# FF_daily_counts = gbff.groupby(gbff.start_date.dt.date).size().cumsum().reset_index()\n",
    "# FF_daily_counts.columns=['date','FF_counts']\n",
    "\n",
    "# #expected\n",
    "# expected = FF_daily_counts.copy()\n",
    "# expected.date = expected.date + datetime.timedelta(days=150) \n",
    "# # cutoff_date_dt = pd.to_datetime(datetime.datetime(year=2023,month=7,day=31)).date()\n",
    "\n",
    "\n",
    "# # ECMC Daily cumulative plot\n",
    "# ECMC_daily_counts = outdf.groupby(outdf.date.dt.date).size().cumsum().reset_index()\n",
    "# ECMC_daily_counts.columns=['date','ECMC_counts']\n",
    "\n",
    "# spacer = datetime.timedelta(days=20)\n",
    "\n",
    "# plt.figure(figsize=(6, 6))\n",
    "# plt.plot(FF_daily_counts.date, FF_daily_counts.FF_counts, linestyle='-',color='grey')# label=label1)\n",
    "# plt.plot(expected.date, expected.FF_counts, marker='o', linestyle='-',)# label=label1)\n",
    "# plt.plot(ECMC_daily_counts.date, ECMC_daily_counts.ECMC_counts, marker='o', linestyle='-',)# label=label1)\n",
    "# # plt.plot(df2[date_column], df2[counts_column], marker='o', linestyle='-', label=label2)\n",
    "\n",
    "# plt.title('ECMC chemical disclosures by number of wells\\nin reference to FracFocus disclosures')\n",
    "# plt.xlabel('Date')\n",
    "# plt.ylabel('Counts')\n",
    "# plt.xlim(FF_daily_counts.date.min()-spacer,ECMC_daily_counts.date.max()+spacer)\n",
    "# plt.grid(True)\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.legend(['fracking start date (by FF data)',\n",
    "#             'expected disclosure',\n",
    "#             'Actual disclosure to ECMC'])  # Add legend to distinguish the lines\n",
    "\n",
    "\n",
    "# # Annotations\n",
    "# first_day_dt = pd.to_datetime('2023-08-01').date()\n",
    "# deadline_dt = (pd.to_datetime('2023-08-01') + pd.Timedelta(days=150)).date()\n",
    "\n",
    "# # Find the y-values for the annotations\n",
    "# first_day_y = FF_daily_counts.get(first_day_dt, 0)  # Get y-value, default to 0 if not found\n",
    "# deadline_y = 0 #daily_counts.get(deadline_dt, 0)\n",
    "\n",
    "# # Annotate the first day\n",
    "# plt.annotate(\n",
    "#     'July 31, 2023 \\nLaw goes into effect',\n",
    "#     xy=(first_day_dt, first_day_y),\n",
    "#     xytext=(first_day_dt, first_day_y + 900),  # Adjust y-offset as needed\n",
    "#     arrowprops=dict(facecolor='orange', shrink=0.05),\n",
    "#     horizontalalignment='left'\n",
    "# )\n",
    "\n",
    "# # Annotate the deadline\n",
    "# plt.annotate(\n",
    "#     'First disclosures\\nexpected',\n",
    "#     xy=(deadline_dt, 0),\n",
    "#     xytext=(deadline_dt, deadline_y + 700),  # Adjust y-offset as needed\n",
    "#     arrowprops=dict(facecolor='red', shrink=0.05),\n",
    "#     horizontalalignment='center'\n",
    "# )\n",
    "\n",
    "# display(md('---\\n# Diclosure of fracking chemical disclosures '))\n",
    "# display(md('### Using FracFocus disclosures as a reference\\n\\n'))\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76b2219-c4e9-49a6-8d66-9d6da2183b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## add in wells_df locations that are within the law, but not in FF or ECMC\n",
    "# c = wells_df.spud>law_begins\n",
    "# c1 = wells_df.api10.isin(FFapis)\n",
    "# recent_wells = wells_df[c& ~(c1)]\n",
    "# gb1 = recent_wells.groupby('location',as_index=False).size()\n",
    "# gb2 = recent_wells.groupby('location',as_index=False)[['Operator']].last()\n",
    "# wells_extra = pd.merge(gb1,gb2,on='location',how='left')\n",
    "# extra_locs = wells_extra.location.unique().tolist()\n",
    "# wells_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf63ea00-2995-441e-a2a6-2bdec1ea4d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # are there locations in extras that aren't in FF\n",
    "# mg[mg.location.isin(extra_locs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e11b835-a3b5-4278-847b-698f6fa060a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(wells_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bef59f5-6879-4342-ac48-5786d66aa194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# last_repo = datetime.datetime(year=2025,month=3,day=24)\n",
    "# law_begins = datetime.datetime(year=2023,month=7,day=31)\n",
    "\n",
    "# # fetch data set\n",
    "# df = pd.read_parquet(os.path.join(hndl.sandbox_dir,'workdf.parquet'),\n",
    "#                columns=['APINumber','DisclosureId','bgStateName','date','OperatorName','bgCAS','mass',\n",
    "#                        'bgCountyName','in_std_filtered','JobStartDate','TradeName'],\n",
    "#                filters=[('bgStateName','==','colorado'),\n",
    "#                         ('in_std_filtered','==',True),\n",
    "#                         ]\n",
    "#               )\n",
    "\n",
    "# df = df[df.date>law_begins]\n",
    "# df['start_date'] = pd.to_datetime(df.JobStartDate,errors='coerce').dt.date\n",
    "# df['start_date'] = pd.to_datetime(df.start_date,errors='coerce')\n",
    "# gb = df.groupby('DisclosureId',as_index=False)[['APINumber','OperatorName','bgCountyName',\n",
    "#                                                 'start_date','date']].first()\n",
    "# # gb1 = gb.groupby('bgStateName',as_index=False)['DisclosureId'].count().rename({'DisclosureId':'Number of disclosures'},axis=1)\n",
    "\n",
    "# # gb2 = gb.groupby(['bgStateName','bgCountyName'],as_index=False)['DisclosureId'].count()\n",
    "# # gb2 = gb2.groupby('bgStateName',as_index=False)['bgCountyName'].count().rename({'bgCountyName':'Number of counties'},axis=1)\n",
    "\n",
    "# # gb3 = gb.groupby('bgStateName',as_index=False)['date'].agg(['min','max']).rename({'min':'earliest',\n",
    "# #                                                                                   'max':'latest'},axis=1)\n",
    "# # mg = pd.merge(gb1,gb2,on='bgStateName',how='left')\n",
    "# # mg = pd.merge(mg,gb3,on='bgStateName',how='left')\n",
    "# # mg = mg.rename({'bgStateName':'State'},axis=1)\n",
    "# # # mg = mg.reset_index(drop=True)\n",
    "# # mg.State = '<center><h3>'+mg.State.str.title().map(lambda x: th.getStateLink(x,x))+'</h3></center>'\n",
    "# # mg = mg.sort_values('Number of disclosures',ascending=False)\n",
    "\n",
    "# import itables.options as opt\n",
    "# opt.order = []  # no sorting\n",
    "\n",
    "# iShow(gb.reset_index(drop=True))\n",
    "# # gb.info()\n",
    "\n",
    "# work_dir = r\"G:\\My Drive\\webshare\\scrape_data\\Colorado\\ECMC_tracker\"\n",
    "# welldf_fn = os.path.join(work_dir,'ECMC_welldf.parquet')\n",
    "\n",
    "# # First time only\n",
    "# # welldf = pd.DataFrame({'APINumber':[],'DisclosureId':[],\n",
    "# #                        'locationID':[],'OperatorName':[],\n",
    "# #                        'ECMC_op':[],'bgCountyName':[],\n",
    "# #                        'start_date':[],'date':[]})\n",
    "# # welldf.to_parquet(welldf_fn)\n",
    "# welldf = pd.read_parquet(welldf_fn)\n",
    "# welldf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d5f41d-2c1d-4749-828e-30c1f33dc13a",
   "metadata": {},
   "source": [
    "### Populate welldf with current disclosures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e7bb14-d454-4785-a76e-5ac49ba95d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlist = welldf.DisclosureId.unique().tolist()\n",
    "c = ~gb.DisclosureId.isin(dlist)\n",
    "both = pd.concat([welldf,gb[c]])\n",
    "both"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e9509a-9978-4173-aa32-0c9447b6a7c2",
   "metadata": {},
   "source": [
    "### Fetch COGIS data on all disclosures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6086de-3d56-419f-a90d-25da18602f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "####  REDO WHEN ADDING NEW DATA\n",
    "\n",
    "# import scrape.Colorado.CO_scraper_support as coss\n",
    "# def make_soup_for_well(APINumber):\n",
    "#     rooturl = \"https://ecmc.state.co.us/cogisdb/Facility/FacilityDetailExpand?api=\"\n",
    "#     url = rooturl+ APINumber[2:-4]\n",
    "#     # print(url)\n",
    "#     html_content = coss.fetch_html(url)\n",
    "#     # print(html_content)\n",
    "#     # print('\\n'+url)\n",
    "#     # print(\"Recycled water\" in html_content)\n",
    "#     return coss.make_soup(html_content)\n",
    "\n",
    "# def get_location_id(soup):\n",
    "#     # Find the <td> element containing \"LocationID:\"\n",
    "#     location_id_td = soup.find('td', string='LocationID:')\n",
    "    \n",
    "#     if location_id_td:\n",
    "#         # Get the next sibling (the <td> with the value)\n",
    "#         value_td = location_id_td.find_next_sibling('td')\n",
    "#         if value_td:\n",
    "#             # Extract the text and convert it to an integer\n",
    "#             location_id_value = int(value_td.text)\n",
    "#             return location_id_value  # Output: 455576\n",
    "#         else:\n",
    "#             print(\"Error: Could not find sibling td with the value.\")\n",
    "#     else:\n",
    "#         print(\"Error: Could not find td containing 'LocationID:'\") \n",
    "    \n",
    "\n",
    "# def get_ECMC_operator(soup):\n",
    "#     # Find the <td> element containing \"Operator:\"\n",
    "#     operator_td = soup.find('td', string='Operator:')\n",
    "    \n",
    "#     if operator_td:\n",
    "#         # Get the next sibling (the <td> with the value)\n",
    "#         value_td = operator_td.find_next_sibling('td')\n",
    "#         if value_td:\n",
    "#             # Extract the text\n",
    "#             operator_value = value_td.text.strip()  # Remove leading/trailing spaces\n",
    "#             output = operator_value.split('(')[0]\n",
    "#             return output\n",
    "#         else:\n",
    "#             print(\"Error: Could not find sibling td with the value.\")\n",
    "#     else:\n",
    "#         print(\"Error: Could not find td containing 'Operator:'\")    \n",
    "\n",
    "# #  fetch ECMC data for the new disclosures\n",
    "# def get_ECMC_data(APINumber):\n",
    "#     soup = make_soup_for_well(APINumber)\n",
    "#     locID = get_location_id(soup)\n",
    "#     ECMCop = get_ECMC_operator(soup)\n",
    "#     return (locID,ECMCop)\n",
    "# locs = []\n",
    "# ops = []\n",
    "\n",
    "# # tmp = both[:5].copy()\n",
    "# for i,row in both.iterrows():\n",
    "#     print(i,end=' ')\n",
    "#     if type(row.locationID) == 'str':\n",
    "#         print(f'skipping {row.APINumber}')\n",
    "#         locs.append(row.locationID)\n",
    "#         ops.append(row.ECMC_op)\n",
    "#         continue\n",
    "#     else:\n",
    "#         tup = get_ECMC_data(row.APINumber)\n",
    "#         locs.append(tup[0])\n",
    "#         ops.append(tup[1])\n",
    "# # \n",
    "# both.locationID = locs\n",
    "# both.ECMC_op = ops\n",
    "# both.to_parquet(welldf_fn)\n",
    "# both"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dd8a4e-3f7e-453b-b5c7-cf558f9825a7",
   "metadata": {},
   "source": [
    "## get ECMC locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2a57b1-22e0-494f-af88-5a682088d21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://ecmc.state.co.us/depot/Stats/ChemicalDisclosures/Index/Locations\"\n",
    "# t = pd.read_html(url)\n",
    "# # print(len(t))\n",
    "# eLocs = t[0].copy()\n",
    "# eLocs['locationID'] = eLocs['Location Number']\n",
    "# mg = pd.merge(both,eLocs[['locationID','Location Name','Last Disclosure Update']],on='locationID', how='outer')\n",
    "# print(f'Total number of unique \"locations\" (well pads): {len(mg.locationID.unique())}')\n",
    "# c = mg['Location Name'].notna()\n",
    "# print(f'Number of locations with an ECMC disclosure: {len(mg[c].locationID.unique())}')\n",
    "# mg['status'] = np.where(mg.APINumber.isna(),'no_FF','has_FF')\n",
    "# mg.status = np.where(mg['Location Name'].isna(), mg.status + ' no_ECMC', mg.status + ' has_ECMC')\n",
    "# mg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5064b321-bb61-48c0-9a32-6849241bd7fb",
   "metadata": {},
   "source": [
    "### Show data from one location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9978ad1b-063d-45fc-9a96-3dd61a39c127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_loc = 477204\n",
    "# ff_api = mg[mg.locationID==target_loc].APINumber.unique().tolist()\n",
    "# print(f'Number of wells in FF at this location: {len(ff_api)}')\n",
    "# print(ff_api)\n",
    "# ff_cas = df[df.APINumber.isin(ff_api)].groupby('bgCAS', as_index=False)['mass'].sum()\n",
    "# ff_cas\n",
    "# ff_tn = df[df.APINumber.isin(ff_api)].groupby('TradeName', as_index=False).size()\n",
    "# ff_tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c6b198-f8a6-4029-9f8f-3c2933bc6df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = pd.read_html(f\"https://ecmc.state.co.us/depot/Stats/ChemicalDisclosures/Location/{target_loc}\")\n",
    "# ecmc_cas = out[0]\n",
    "# casmg = pd.merge(ecmc_cas,ff_cas,left_on='CAS Number', right_on='bgCAS',how='outer')\n",
    "# casmg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b00c0d0-0779-406a-83eb-f0760356b904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ecmc_form46a = out[1]\n",
    "# ecmc_form46a['date'] = pd.to_datetime(ecmc_form46a['Submit Date'])\n",
    "# c = ecmc_form46a.date==ecmc_form46a.date.max()\n",
    "# pdf_dir = r\"G:\\My Drive\\webshare\\scrape_data\\Colorado\\imaged_docs\"\n",
    "# docnum = ecmc_form46a[c]['Document #'].tolist()[0]             \n",
    "# pdffn = os.path.join(pdf_dir,f'{docnum}.pdf')\n",
    "# pdffn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9537214b-ae1b-44a0-b549-05383ae893ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# known_ecmc_prod_names = pd.read_parquet(os.path.join(pdf_dir,'products_set.parquet'))\n",
    "# known_ecmc_prod_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec185a64-17db-4e5b-b1af-c161a5eb78e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scrape.Colorado.CO_imaged_docs_extract as cide\n",
    "# text = cide.get_pdf_text(pdffn)\n",
    "# ecmc_prod_names = cide.extract_product_names(text,known_ecmc_prod_names.TradeName.unique().tolist())\n",
    "# ecmc_api10 = cide.extract_APINumbers(text)\n",
    "# print(ecmc_prod_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29202358-4dc7-4b12-9e1c-2b64f73d8ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prod_names = pd.DataFrame({'TradeName':df.TradeName.unique().tolist()})\n",
    "# prod_names.to_parquet(os.path.join(r\"C:\\MyDocs\\integrated\\gwa_local\\tmp\",'CO_prod_names.parquet'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5aace19-d090-4ddd-aedc-1a06e330082a",
   "metadata": {},
   "source": [
    "## get well data for spud date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7e461b-43be-4bbe-a83f-4fdcf3034292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn = r\"G:\\My Drive\\webshare\\scrape_data\\Colorado\\Wells.csv\"\n",
    "# cowells = pd.read_csv(fn,low_memory=False,usecols=['API,C,10','Spud_Date,D','Operator,C,50'],\n",
    "#                      dtype={'API,C,10':'str'})\n",
    "# cowells.columns = ['api','operator','spud']\n",
    "# cowells['spud_date'] = pd.to_datetime(cowells.spud)\n",
    "# cowells['APINumber'] = '05'+cowells.api+'0000'\n",
    "# cowells = cowells.drop(['api','spud'],axis=1)\n",
    "# cowells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2137f5-5e28-4f77-b2d7-473de3d374e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mg = mg.merge(cowells[['spud_date','APINumber']],on='APINumber',how='left')\n",
    "mg['spud_start_diff_days'] = (mg.start_date - mg.spud_date).dt.days\n",
    "mg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f831f1-1ed3-48e8-b02d-7c8d8cf85359",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
