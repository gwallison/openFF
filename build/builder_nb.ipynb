{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e3823ba-1c6f-4b87-849a-8ca8bdc68e5d",
   "metadata": {
    "id": "9e3823ba-1c6f-4b87-849a-8ca8bdc68e5d",
    "tags": []
   },
   "source": [
    "| <div> <img src=\"https://storage.googleapis.com/open-ff-common/openFF_logo.png\" width=\"100\"/></div>|<h1>Adding New Disclosures to the Open-FF Data:<br><br>Download, Curate, Assemble, Test, and Archive<br></h1>|\n",
    "|---|---|\n",
    "\n",
    "<!--\n",
    "<center><a href=\"https://www.fractracker.org/\" title=\"FracTracker Alliance\"><img src=\"https://storage.googleapis.com/open-ff-common/2021_FT_logo_icon.png\" alt=\"FracTracker logo\" width=\"100\" height=\"100\"><br>Sponsored by<br> FracTracker Alliance</a></center>| -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63c4d54-2443-4aea-a7dd-520b591cc05a",
   "metadata": {
    "id": "af0fd3b5-cdf7-4f5f-9310-0447845d2dbe"
   },
   "outputs": [],
   "source": [
    "# fetch the Open-FF code repository and master data file from remote storage\n",
    "# For use in COLAB, the following lines should be uncommented; \n",
    "#   comment all lines if running locally\n",
    "\n",
    "# !git clone https://github.com/gwallison/openFF.git &>/dev/null;\n",
    "# !pip install itables  &>/dev/null;\n",
    "# !pip install geopandas  &>/dev/null;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdff9d29-696c-4d86-a137-a6a55ae5fa77",
   "metadata": {
    "id": "af0fd3b5-cdf7-4f5f-9310-0447845d2dbe"
   },
   "outputs": [],
   "source": [
    "# %run openFF/build/builder_nb_support.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e3136e-29a8-4c02-8863-739c4f1336cb",
   "metadata": {
    "id": "d9e3136e-29a8-4c02-8863-739c4f1336cb"
   },
   "outputs": [],
   "source": [
    "# Local - The lines below should stay commented unless running locally, they would replace the cell above\n",
    "# assumes that the code is already available in the local environment\n",
    "import sys\n",
    "sys.path.insert(0,'c:/MyDocs/integrated/') # adjust to your setup\n",
    "%run builder_nb_support.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69efe94-8f5e-481c-b1fa-5a7df0eec7b3",
   "metadata": {
    "id": "1fc7469d-b62a-40c5-9e2d-75845620b5b1",
    "tags": []
   },
   "source": [
    "# Set up\n",
    "First we start by constructing a workspace and collecting the resources needed.\n",
    "\n",
    "**Directories constructed:**  These are all within a directory called **sandbox** in the openFF/build directory/.  As you go through this process, you will interact with files in most of these directories.\n",
    "| directory name | description |\n",
    "| ---: | :--- |\n",
    "|**orig_dir**| expanded zip files, downloaded external files, etc: files used as a model for the next round, but not to be directly saved|\n",
    "|**work_dir**| This is the working directory where new curation files created by these routines are kept. These 'generated' files are saved at the end of the process into either the repository or other archives.|\n",
    "|**ext**| non-FracFocus data files used in constructing the Open-FF data set |\n",
    "|**final**| the place for final files, archives and repositories. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29128ef1-33b5-4f2a-bf46-98bcbc32d6b7",
   "metadata": {
    "id": "29128ef1-33b5-4f2a-bf46-98bcbc32d6b7"
   },
   "outputs": [],
   "source": [
    "# Control download: typically set to True\n",
    "#    set to False if you can skip the downloading part of the repo and the external data, for example, during testing.\n",
    "\n",
    "download_repo_flag = True\n",
    "download_ext_flag = True\n",
    "download_FF_flag = True\n",
    "create_raw_flag = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d28d1d7-6123-45d6-bcbb-91378203672b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 327
    },
    "id": "4d28d1d7-6123-45d6-bcbb-91378203672b",
    "outputId": "34821dab-4cd7-4ad1-a47a-5aab206bf05f"
   },
   "outputs": [],
   "source": [
    "create_and_fill_folders(download_repo_flag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d996c830-b6b5-43e5-b9d8-0dec6d803364",
   "metadata": {
    "id": "d996c830-b6b5-43e5-b9d8-0dec6d803364"
   },
   "source": [
    "## Download external files used to assemble final data set\n",
    "To do:\n",
    "- make list of external databases and when they were compiled\n",
    "- reorg so that you don't have to download everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860db2a3-5e5e-4f63-945e-9e15d1d04183",
   "metadata": {
    "id": "860db2a3-5e5e-4f63-945e-9e15d1d04183"
   },
   "outputs": [],
   "source": [
    "get_external_files(download_ext_flag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523a3934-b10c-4962-aa20-2af70b95827f",
   "metadata": {
    "id": "523a3934-b10c-4962-aa20-2af70b95827f",
    "tags": []
   },
   "source": [
    "## Download raw files from FracFocus\n",
    "To do:\n",
    "- refactor comparison with previous download\n",
    "- make trap to detect addition of new fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5590894b-8e3c-4d9d-8813-e92231a0bf77",
   "metadata": {
    "id": "5590894b-8e3c-4d9d-8813-e92231a0bf77"
   },
   "outputs": [],
   "source": [
    "\n",
    "download_raw_FF(download_FF_flag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e77dd38-613a-468d-9e1f-62291a33552a",
   "metadata": {
    "id": "5e77dd38-613a-468d-9e1f-62291a33552a",
    "tags": []
   },
   "source": [
    "## Create master raw FracFocus set as file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ad0c84-4143-4874-b64b-488db9a1cc08",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "454ce504-20ca-4948-a431-8b52353c65ca",
    "outputId": "9eced4bf-07be-4292-ad1d-5317af197ade",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "create_master_raw_df(create_raw_flag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b652564-05ea-4908-b443-61b8559befd3",
   "metadata": {
    "id": "9b652564-05ea-4908-b443-61b8559befd3"
   },
   "source": [
    "#### Add new disclosures to Disclosure ID file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8920a458-b74a-47bd-bdc3-a72e31d18c68",
   "metadata": {},
   "source": [
    "## One Time Change:\n",
    "Due to the transition to FracFocus version 4 that happened on Dec 4, 2023, a transition \"upload_dates.parquet\"  was used as a replacement to the original.  The primary difference is that it includes the appropriate `DisclosureId` values that are replacing the `UploadKey` values.  that file can now serve as a translation file between old and new keys to the disclosures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1760afd9-6a8c-4efc-b8a2-20613036d2bb",
   "metadata": {
    "id": "1760afd9-6a8c-4efc-b8a2-20613036d2bb"
   },
   "outputs": [],
   "source": [
    "\n",
    "update_upload_date_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b980b90-c3ea-450f-88d0-e77092e14f32",
   "metadata": {
    "id": "1b980b90-c3ea-450f-88d0-e77092e14f32",
    "tags": []
   },
   "source": [
    "# Curation steps\n",
    "These steps are a mix of automated and hand-performed curation tasks. The hand performed tasks require the user to examine database values in spreadsheets and then to make and record decisions on those values about individual records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a80081f-4ee8-43e1-b948-fbfee984affb",
   "metadata": {
    "id": "4a80081f-4ee8-43e1-b948-fbfee984affb",
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "## `CASNumber` and `IngredientName` curation tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a07cdb-6364-4ae4-8f40-4dcbf68a9fb9",
   "metadata": {
    "id": "66a07cdb-6364-4ae4-8f40-4dcbf68a9fb9",
    "tags": []
   },
   "source": [
    "Open-FF uses both raw input fields `CASNumber` and `IngredientName` to clarify chemical identity in each record.  These two fields **should** agree on the identity, but often only one field provides unambiguous identification (usually `CASNumber`) and sometimes the two are conflicting.  Our target is an accurate `bgCAS`, which is our \"best guess\" at a CAS Registration Number for the material reported in the disclosure.\n",
    "That is,\n",
    "> Unique `CASNumber` | `IngredientName` pair  $\\rightarrow$ `bgCAS`\n",
    "\n",
    "There are currently over 28,000 unique pairs.\n",
    "\n",
    "The curation process outlined below gets our identification as close as possible to our target.  It requires using several sources of information and part of the process includes collecting that information.  Some steps are partially automated whereas other steps require our judgement and are therefore manual.  \n",
    "\n",
    "This process is also incremental - we only need to curate the *new* chemical identifiers in the most recent download.  However, this process can also be used to examine the whole curated set to refine identification performed earlier.  \n",
    "\n",
    "Resources needed to create the CAS-Ing list:\n",
    "- CAS_curated: a list of `CASNumber` values and the tentative `bgCAS` number they imply.\n",
    "- `IngredientName` synonym list: list of synonyms (and associated CAS number) to weigh against `IngredientName`. This is created from a collection of CAS and CompTox references.\n",
    "- `TradeName` values associated with CAS-Ing pairs -- this aspect is still in development, though curators may manually examine TradeNames to make decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6780c49-8b7e-49ea-98d2-2b4b77591ff5",
   "metadata": {
    "id": "a6780c49-8b7e-49ea-98d2-2b4b77591ff5",
    "tags": []
   },
   "source": [
    "### step A - use previous list to find any new `CASNumber` values\n",
    "1. compare list of `CASNumber` values in rawdf to list of `CASNumber` in *olddir/curation_files/cas_curated.csv*\n",
    "1. make and display list of those new ones.\n",
    "\n",
    "#### Next steps for YOU:\n",
    ">Next steps for **new** `CASNumber` (see note below): \n",
    ">- if the implied chemical is not in the CAS references, go to SciFinder and make new entry (manual!)\n",
    ">- otherwise, can skip the SciFinder steps, but go to the CAS_curate step. \n",
    ">\n",
    ">If there are no **new** `CASNumber`, \n",
    ">- skip all the way to the moving the current CAS_curate.csv to *newdir/curation_files/CAS_curate.csv*\n",
    "\n",
    "Note: these \"new\" `CASNumber` values can be completely new chemicals or just a new version of an already used material (for example, we might find '00000050-00-0' for the authoritative CASRN '50-00-0' that is already documented in Open-FF.).   They may also be something that will not resolve into a valid CASRN, for example: 'proprietary by operator'. You will assign appropriate 'bgCAS' values in the curation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d236affb-177d-46f1-8b1e-2a4b3c4cc244",
   "metadata": {
    "id": "d236affb-177d-46f1-8b1e-2a4b3c4cc244"
   },
   "outputs": [],
   "source": [
    "cas_curate_step1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddb345e-576a-4067-b4cf-7bc190803ada",
   "metadata": {
    "id": "3ddb345e-576a-4067-b4cf-7bc190803ada"
   },
   "source": [
    "### Step B - Add chem info from SciFinder of new tentative CAS numbers into CAS_ref files\n",
    "If a chemical on this list hasn't been seen before in FF, we need to add some information into the CAS_ref files.\n",
    "To do that, we currently use SciFinder, which is a product of the Chemical Abstract Service, the naming authority for materials.\n",
    "\n",
    "Save the file in `new_CAS_ref` directory of **work_dir** \n",
    "\n",
    "Once you have saved the file, run the following cell to **verify** that the new `CASNumber`s that you've found to be valid and created a reference for, actually made it into the SciFinder reference.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a6c70e-43ba-4c86-b2b6-2043f90c4c9a",
   "metadata": {
    "id": "73a6c70e-43ba-4c86-b2b6-2043f90c4c9a"
   },
   "outputs": [],
   "source": [
    "cas_curate_step2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5893aa1-9817-4c49-93bb-01efda6722c5",
   "metadata": {
    "id": "d5893aa1-9817-4c49-93bb-01efda6722c5"
   },
   "source": [
    "### Step C - Curate the CAS_to_curate file\n",
    "In this step you will manually edit the *work_dir/CAS_curated_TO_EDIT.csv* file to curate the new `CASNumber` values. There are typically only a handful of lines in this file that you need to curate, just those newly discovered in the latest FF download. \n",
    "\n",
    "Your task is to assign a `curatedCAS` value for each new line, using the clues there.\n",
    "\n",
    "Once you have completed the editing, save the file back to *work_dir/CAS_curated_modified.csv*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d406ed-0fe7-4e4a-8d4f-2f9fa52561d8",
   "metadata": {
    "id": "47d406ed-0fe7-4e4a-8d4f-2f9fa52561d8"
   },
   "source": [
    "#### Step C.1 - Make sure all `CASNumber` values have been curated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704e63eb-1a8a-4df7-8c5e-e2cede407f11",
   "metadata": {
    "id": "704e63eb-1a8a-4df7-8c5e-e2cede407f11"
   },
   "outputs": [],
   "source": [
    "\n",
    "cas_curate_step3()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f60370-c8bc-4a5a-a9f1-416490938582",
   "metadata": {
    "id": "e2f60370-c8bc-4a5a-a9f1-416490938582"
   },
   "source": [
    "---\n",
    "### Step D - Update CompTox data\n",
    "The metadata from EPA's CompTox system informs OpenFF in a number of ways. Now that we have a full CAS list, we need to update the CompTox data. \n",
    "**If no new CAS numbers were added to CAS_curated.csv, you can skip this step and jump to the CAS | Ing processing**\n",
    "\n",
    "1. Open [CompTox batch search](https://comptox.epa.gov/dashboard/batch-search)\n",
    "1. Under \"Select Input Type(s)\", check \"CASRN\"\n",
    "1. Open the  *work_dir/comptox_search_list.csv* file in something like Excel or OpenOffice. (If you can't find this file, you may not need to run this step - no new CAS numbers?).\n",
    "1. Copy and paste all CAS numbers in the `curatedCAS` column into the CompTox webpage \"Enter Identifiers to Search\" box.  You can skip the non_CAS numbers like 'proprietary'. They mean nothing to CompTox.\n",
    "1. On the Comptox page, click the \"Choose Export Options\" button.\n",
    "1. Under \"Choose Export Format,\" select \"Excel.\"\n",
    "1. In the \"Chemical Identifiers\" section, make sure that the following are checked (but no more than these):\n",
    "- Chemical Name\n",
    "- DTXSID\n",
    "- IUPAC Name\n",
    "8. Under the \"Presence in Lists\" table, click the check box in the header that selects ALL lists.  This will be used to map what lists each chemical is part of.\n",
    "1. Under \"Enhanced Data Sheets,\" select \"Synonyms and Identifiers\" (This is has been broken on the EPA site in the past, see below)\n",
    "1. Finally, click \"Download Export File\". This can take several minutes, or even stall if EPA's servers have heavy use.\n",
    "1. Once the file has been downloaded to your machine, RENAME it \"comptox_batch_results.xlsx\" (don't open it, just rename it!) \n",
    "    - (**NOTE this feature - the \"Download Export File\" process - has occasionally not worked.  It does not complete but hangs indefinitely.**  The current work-around is to \n",
    "        - Deselect the \"Synonyms and Identifiers\" checkbox and click \"Download Export File\" again. You won't be able to get the synonym data, but will still be able to update the name data.)\n",
    "1. Move that file to *work_dir*\n",
    "\n",
    "### Next, we fetch a fresh version of the CompTox Lists metadata:\n",
    "\n",
    "- Go to the [EPA CompTox **list** page](https://comptox.epa.gov/dashboard/chemical-lists)\n",
    "- Click on the \"Export\" button in the upper right, and select the \"Excel\" option.  This will download a file to your computer.\n",
    "- Rename that file (without opening it) as \"comptox-chemical-lists-meta.xlsx\" and move it to work_dir.\n",
    "\n",
    "1. Run the following cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e4c9e8-ebf2-49c4-9781-7d7f7e4ce693",
   "metadata": {
    "id": "c4e4c9e8-ebf2-49c4-9781-7d7f7e4ce693"
   },
   "outputs": [],
   "source": [
    "update_CompTox_lists()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9791f6-bc74-492f-aa48-84d240682a6c",
   "metadata": {},
   "source": [
    "### Finally, capture the ChemInformatics\n",
    "\n",
    "**Note that this is currently working slowly and often hanging. If this doesn't work, this step can be skipped, and the previous repo's information will be used instead.**\n",
    "\n",
    "\n",
    "- open the [ChemInformatics Modules](https://www.epa.gov/comptox-tools/cheminformatics) that is part of the CompTox system. \n",
    "- click on the \"Hazard\" module, then click on the magnifying glass.\n",
    "- using the *work_dir/comptox_search_list.csv* list again, paste all CASRN into the search box (\"search by identifiers\" tab), and click \"Search\".\n",
    "- When the module returns with a list of found compounds, save them to the cart by clicking the \"Cart +\" icon.\n",
    "- Back at the Hazard Module screen, press the \"Cart\" icon to generate a report.  For this long list, this process can take a few minutes.  \n",
    "- Now, save the results into TWO files to use in Open-FF:\n",
    "    - click the \"export to XLSX\" icon in the upper right, and wait again.  Move that file directly into the *work_dir/new_CHEMINFO_ref* folder\n",
    "    - click the \"export to SDF\" icon in the upper right, and wait again.  Move that file directly into the *work_dir/new_CHEMINFO_ref* folder.\n",
    "- Next, we will grab the safety data for these chemicals.  Click on the \"Safety\" module (the safety glasses icon).\n",
    "- Click on the \"Cart\" icon to generate a report for the 1400+ chemicals still in the cart.  This will take a while.\n",
    "- Now, save the results into one file to use in Open-FF:\n",
    "    - click the \"export to XLSX\" icon in the upper right, and wait again.  Move that file directly into the *work_dir/new_CHEMINFO_ref* folder\n",
    "\n",
    "\n",
    "- Finish by running the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176ac8f6-0eed-4c39-92b6-eb1862d00534",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_ChemInformatics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7a3fd6-ff98-4d29-9c97-35fa76c4ab9d",
   "metadata": {
    "id": "0c7a3fd6-ff98-4d29-9c97-35fa76c4ab9d",
    "tags": []
   },
   "source": [
    "---\n",
    "## Start CAS|Ing processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30d0397-53c5-4c6e-a5ec-ae86f4cb4e9c",
   "metadata": {
    "id": "d30d0397-53c5-4c6e-a5ec-ae86f4cb4e9c"
   },
   "outputs": [],
   "source": [
    "casing_step1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e40d3f-b82a-46a6-8331-fda2cd9f9e9c",
   "metadata": {
    "id": "38e40d3f-b82a-46a6-8331-fda2cd9f9e9c"
   },
   "source": [
    "### step E - curate the new CAS|Ing pairs \n",
    "\n",
    "- make any desired changes to casing_TO_CURATE.csv.  For any given pair, **there should be only ONE line with 'xxx' in 'picked'**.  \n",
    "- save file as *casing_modified.csv* in **work_dir**\n",
    "- then run the following code.  This step will keep only those lines where 'picked'=='xxx' and it will add today's date as the first seen date.\n",
    "\n",
    "It will then add these lines to the master casing_curated file that will be used in subsequent steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6245ab99-deb9-4580-ba2c-3933e3dc6664",
   "metadata": {
    "id": "6245ab99-deb9-4580-ba2c-3933e3dc6664"
   },
   "outputs": [],
   "source": [
    "\n",
    "casing_step2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54564d48-c915-4e8a-8a68-1b784cf5d7e2",
   "metadata": {
    "id": "54564d48-c915-4e8a-8a68-1b784cf5d7e2"
   },
   "source": [
    "### step F - Verify that all CAS/Ing pairs are curated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27aab4b-5448-42a0-8ddf-3d650c954688",
   "metadata": {
    "id": "b27aab4b-5448-42a0-8ddf-3d650c954688"
   },
   "outputs": [],
   "source": [
    "\n",
    "casing_step3()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb49d7e-5e4d-4e18-8107-43d8d1d4e6cc",
   "metadata": {
    "id": "0eb49d7e-5e4d-4e18-8107-43d8d1d4e6cc",
    "tags": []
   },
   "source": [
    "## Company Name curation tasks\n",
    "\n",
    "The company names used in FracFocus are not standardized; searching for all records of a company using the raw FracFocus data can be a tedious and frustrating task.   Open-FF uses a translation table to take raw company names (`OperatorName` and `Supplier`) and cluster them into categories that refer to the same company.  \n",
    "\n",
    "The cells below first finds new company names that need curation attention and stores them in a file called *company_xlateNEW.csv*.  Typically, for about 1000 new disclosures, there are about 50 new names to curate, with many being slight variations on already curated names or brand new companies.  The users job is to do that curation (it usually takes just a few minutes).  The user saves that curated file and that will be used to build a new data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd680c2-1ac6-4bbe-b736-d7b64a936db9",
   "metadata": {
    "id": "cbd680c2-1ac6-4bbe-b736-d7b64a936db9"
   },
   "outputs": [],
   "source": [
    "companies_step1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c71eb26-a7da-4f34-bbe8-13b57590c087",
   "metadata": {
    "id": "4c71eb26-a7da-4f34-bbe8-13b57590c087"
   },
   "source": [
    "### Now curate the new company names\n",
    "Edit the *company_xlateNEW.csv* file so that `xlateName` is acceptable, the `first_date` is filled out, and the `status` is set to **curated**. \n",
    "\n",
    "Save those changes as *work_dir/company_xlate_modified.csv*. \n",
    "\n",
    "Run the following cell and verify that you have no company names to curate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427f7c37-4960-4c2d-aeab-8c15ab3ab8d8",
   "metadata": {
    "id": "427f7c37-4960-4c2d-aeab-8c15ab3ab8d8"
   },
   "outputs": [],
   "source": [
    "companies_step2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b880aba-e33e-4542-97ec-3016014d0d86",
   "metadata": {
    "id": "0b880aba-e33e-4542-97ec-3016014d0d86",
    "tags": []
   },
   "source": [
    "## Location curation tasks\n",
    "\n",
    "Like the other text fields in FracFocus, state and county names are not required to be standardized.  We try to create curated, standardized versions where we can to help with location errors detection.  Typically, very few new locations are added and so curation is often not even required with this data set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f21d4a3-34f3-4ced-85be-42d17607424b",
   "metadata": {
    "id": "3f21d4a3-34f3-4ced-85be-42d17607424b"
   },
   "outputs": [],
   "source": [
    "location_step1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879bd036-a8ea-4a88-a01c-6e7db09f0d60",
   "metadata": {
    "id": "879bd036-a8ea-4a88-a01c-6e7db09f0d60"
   },
   "source": [
    "### Curate results\n",
    "**If there are new locations**, curate the *work_dir/location_curatedNEW.csv* file and save to *work_dir/location_curated_modified.csv*\n",
    "\n",
    "Then run the location check again to make sure you curated all the new locations (or to move the last repo's curation into workdir): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade7d71e-6ed6-48d3-91f8-60eaa2422563",
   "metadata": {
    "id": "ade7d71e-6ed6-48d3-91f8-60eaa2422563"
   },
   "outputs": [],
   "source": [
    "\n",
    "location_step2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9903b2-3d6e-4821-9278-cf285b8377a2",
   "metadata": {
    "id": "af9903b2-3d6e-4821-9278-cf285b8377a2",
    "tags": []
   },
   "source": [
    "## Water carrier detection\n",
    "To perform accurate calculation of mass, it is critical that the water carrier records in disclosures are identified.\n",
    "\n",
    "In this current version of Open-FF, all water carrier determinations are performed with code.  No hand-curation is used. We came to the conclusion that, in the irregular disclosures that would be a target for hand curation, there are too many moving parts to make consistent decisions over the whole set especially with new disclosures being added all the time.  By using only coded algorithms to detect the carriers, we can apply consistant rules over the entire set.   \n",
    "\n",
    "The current set of algorithms rejects about 54,000 disclosures as being clearly ineligible for carrier detection (43,000 simply because they lack ingredient data).  Of the remaining 150,000, about 1% are not caught by the detection algorithms.  Data on those are available in a saved file here for user examination. While calculated masses will not be performed on that small set, `MassIngredient` may still be explored. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d336c0f-1ac6-4482-8b71-e17260ed819c",
   "metadata": {
    "id": "7d336c0f-1ac6-4482-8b71-e17260ed819c"
   },
   "outputs": [],
   "source": [
    "carrier_step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d390778-fb9c-44ec-805e-b9d6bde10040",
   "metadata": {
    "id": "8d390778-fb9c-44ec-805e-b9d6bde10040",
    "tags": []
   },
   "source": [
    "# Build and save Open-FF data set\n",
    "\n",
    "**Start these steps only after all curation steps have been completed successfully!**\n",
    "\n",
    "This step takes all of the files created in the curation steps and applies them together to the raw data.  Additionally, hooks to external data sources are used to create fields that better identify chemicals, locations etc.  The result of this step is a set of tables that can be used to further build a flat data set (such as a CSV file) or even a relational database.\n",
    "\n",
    "**Also, before you take these next steps, look through "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6bc31f-d464-4e5b-b68a-957486d02735",
   "metadata": {
    "id": "3e6bc31f-d464-4e5b-b68a-957486d02735"
   },
   "outputs": [],
   "source": [
    "builder_step1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627555cd-e3b3-400c-b388-f8d7dc8b02c0",
   "metadata": {
    "id": "627555cd-e3b3-400c-b388-f8d7dc8b02c0"
   },
   "outputs": [],
   "source": [
    "builder_step2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d497ba-9232-4ce1-9b32-72ef57bdd1fe",
   "metadata": {
    "id": "92d497ba-9232-4ce1-9b32-72ef57bdd1fe",
    "tags": []
   },
   "source": [
    "## Create flat data set and test it\n",
    "This step uses the set of tables created earlier to build a single 'flat' data file as well as to run some basic tests on the new data set.  Note that because the full data set is very large (too big for excel) and CSV files are cumbersome at this size, we are using the **parquet** format which is much faster and takes up far less space.  To create an equivalent CSV file, see this XXXXXXX\n",
    "\n",
    "**Note that running this notebook in the free version of Colab can, at this step, cause the memory to overflow and reset the kernel.** This seems to depend on a number of factors and while unfortunate, is not fatal.  If you've made it this far, all the materials needed to complete the process are stored on disk.  So to finish up:\n",
    "- rerun the `%run [...]build_nb_support.py` cell at the top of the notebook\n",
    "- run the following steps.  It should complete normally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a0fef7-918d-4c13-8c7f-a0156fe222ec",
   "metadata": {
    "id": "14a19a79-d245-4b50-8b84-db14726c0dbe"
   },
   "outputs": [],
   "source": [
    "builder_step3()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36592e98-d8f8-4a58-99e4-d2d8eda18883",
   "metadata": {
    "id": "36592e98-d8f8-4a58-99e4-d2d8eda18883",
    "tags": []
   },
   "source": [
    "## Make repository\n",
    "One the data set has been created, saved and tested, we construct a \"repository.\"  Once created, this repository is intended to be **read only**, that is, no changes should be made to it.  The idea is that when using a given repository, analysts can depend on it being frozen in time.\n",
    "\n",
    "Still to be done:\n",
    "- include README that describes history of repo.\n",
    "- include code used to make this repo \n",
    "    - BUT exclude git and other hidden folders. Not useful!\n",
    "- make html file of the output of this notebook and include in repo\n",
    "- include list of the versions of the external files used\n",
    "- include archive of zip of bulk download\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2318dd-421b-4b5f-a82b-a63228275b69",
   "metadata": {
    "id": "2b2318dd-421b-4b5f-a82b-a63228275b69"
   },
   "outputs": [],
   "source": [
    "\n",
    "make_repository(create_zip=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6de0c8b-3cc8-48c4-9877-9cc621f101ec",
   "metadata": {
    "id": "f514e508-bfd0-465b-bcf1-c6ac932775f1"
   },
   "source": [
    "## Copy this notebook page into the new repository\n",
    "As a record of the process that created this new repository, use jupyter -> `Save and Export Notebook as...` to create a .HTML file of this notebook's output.  Then move that file to the new repository folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556c0cfd-e873-4fb3-b6f5-69a937f32530",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
